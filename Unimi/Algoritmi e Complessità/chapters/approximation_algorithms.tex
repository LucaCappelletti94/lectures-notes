\providecommand{\main}{..}
\documentclass[\main/main.tex]{subfiles}
\begin{document}

\chapter{Algoritmi di Approssimazione}
\section{Bilanciamento di carico (load balancing)}
Con \textbf{load balancing} si intende il problema di assegnare lavori ad ogni macchina in modo da minimizzare il \textbf{makespan}, cioè il carico massimo assegnato ad una data macchina. Ogni lavoro \(j\) deve lavorare continuamente su una macchina e una macchina può processare solo un lavoro per volta. Si tratta di un problema \textbf{NP-Hard} persino con solo due macchine.
\begin{definition}[Carico]
	Sia \(J(i)\) il sottoinsieme di lavori assegnati alla macchina \(i\)-esima.
	Allora il carico della \(i\)-esima macchina è pari a:
	\[
		L_i = \sum_{j \in J(i)} t_j
	\]
	Dove \(t_j\) è il tempo necessario per processare il lavoro \(j\).
\end{definition}
\begin{definition}[Makespan]
	Con \textbf{makespan} si intende il massimo carico su qualsiasi data macchina:
	\[
		L = \max_{i} L_i
	\]
\end{definition}
\subsection{Algoritmo di List-Scheduling}
Prendiamo in considerazione \(n\) lavori in un ordine fissato. Assegniamo il lavoro \(j\)-esimo alla macchina il cui carico è più piccolo sino ad ora.

\begin{complexity}[List Scheduling]
	L'implementazione del List Scheduling ha complessità computazionale \(O(n\log m)\) utilizzando una coda di priorità.
\end{complexity}

\subsubsection{Analisi}
\begin{lemma}
	Il \textbf{makespan} ottimo \(L^*\) risulta maggiore o uguale del tempo di lavoro massimo.
	\[
		L^* \geq \max_{j} t_j
	\]
	\label{primo_lemma_graham}
\end{lemma}
\begin{proof}
	Banalmente una macchina deve processare il lavoro che consuma più tempo.
\end{proof}
\begin{lemma}
	Il  \textbf{makespan} ottimo \(L^*\) risulta maggiore o uguale della media dei tempi di elaborazione.
	\[
		L^* \geq \frac{1}{m} \sum_{j} t_j
	\]
	\label{secondo_lemma_graham}
\end{lemma}
\begin{proof}
	Il tempo di processo totale è \(T = \sum_{j} t_j\) ed una delle macchine deve fare certamente almeno \(\frac{1}{m}\) del lavoro.
\end{proof}
\begin{theorem}[Teorema di Graham 1966]
	Un algoritmo greedy è una \textbf{2-approximation}, cioè l'ottimo locale individuato dall'algoritmo è al più due volte peggiore dell'ottimo globale.
	\label{graham_theorem}
\end{theorem}
\begin{proof}[Teorema di Graham]
	Prendiamo in considerazione il carico di strozzatura \(L_i\) della macchina \(i\). Sia \(j\) l'ultimo lavoro pianificato sulla macchina \(i\), allora, quando il lavoro \(j\) viene assegnato alla macchina \(i\), questa aveva il carico minore. Il suo carico precedentemente all'assegnamento era pari a:
	\[
		L_i - t_j \Rightarrow L_i - t_j \leq L_k \quad \forall i \leq k \leq m
	\]
	Sommando le disuguaglianze su \(k\) ed applicando il lemma \ref{secondo_lemma_graham} otteniamo:
	\begin{align*}
		L_i - t_j & \leq \frac{1}{m} \sum_{k} L_k &                                                            \\
		          & = \frac{1}{m} \sum_{k} t_k    &                                                            \\
		          & \leq L^*                      & \text{Applichiamo qui il lemma \ref{secondo_lemma_graham}} \\
	\end{align*}
	Quindi applicando il lemma \ref{primo_lemma_graham}:
	\[
		L_i = \underbrace{L_i - t_j}_{\leq L^*} + \underbrace{t_j}_{\leq L^*} \leq 2L^*
	\]
\end{proof}

\subsection{Regola del longest processing time (LPT)}
Ordina \(n\) lavori in ordine decrescente di tempo di elaborazione e quindi esegui usando questa lista l'algoritmo di List-Scheduling.

\begin{observation}
	Se vi sono al più \(m\) lavori, allora l'algoritmo di list-scheduling è ottimo: banalmente si assegna ad ogni macchina un lavoro.
\end{observation}

\begin{lemma}
	Se esistono più lavori che macchine, allora:
	\[
		L^* \geq 2t_{m+1}
	\]
	\label{terzo_lemma_graham}
\end{lemma}
\begin{proof}
	Prendiamo in considerazione i primi \(m+1\) lavori. Il tempo di elaborazione di ognuno è in ordine decrescente, per cui tutti i lavori richiedono un tempo di elaborazione maggiore del tempo \(t_{m+1}\) dell'ultimo lavoro considerato.

	Se vi sono \(m+1\) lavori ed \(m\) macchine, una macchina deve necessariamente dover compiere almeno due lavori.
\end{proof}

\begin{theorem}[Approssimazione della regola LPT]
	La regola LPT è un algoritmo con una \(\frac{3}{2}\)-approximation.

	\textit{Esiste un teorema più sofisticato che dimostra che l'algoritmo sia una \(\frac{4}{3}\)-approximation.}
\end{theorem}
\begin{proof}[Approssimazione della regola LPT]
	La dimostrazione è analoga a quella del teorema \ref{graham_theorem}, ma nella conclusione viene sfruttato il lemma \ref{terzo_lemma_graham}:
	\[
		L_i = \underbrace{L_i - t_j}_{\leq L^*} + \underbrace{\leq \frac{1}{2}L^*} \leq \frac{3}{2} L^*
	\]
\end{proof}

\section{Problema della selezione del numero di centri}
Il problema consiste nel scegliere \(k\) centri \(C\) così che la distanza massima \(r(C)\) da un punto al centroide più vicino è minimizzata.

\subsection{Soluzione con algoritmo greedy}
Posizioniamo il primo centro nella migliore posizione possibile e continuiamo ad aggiungere centri sino a ridurre il raggio ogni volta quanto più possibile.

Ogni nuovo centroide è posizionato in modo da essere quanto più distante possibile da quelli preesistenti.

\begin{property}[Proprietà dell'algoritmo greedy]
	Alla terminazione, tutti i centroidi in \(C\) sono uno a uno distanti almeno quanto il raggio di copertura minimo \(r(C)\).
\end{property}

\begin{lemma}
	Sia \(C^*\) l'insieme ottimale dei centroidi. Allora vale che:
	\[
		r(C) \leq 2r\rnd{C^*}
	\]
\end{lemma}
\begin{proof}
	Procediamo per assurdo e assumiamo che \(r(C^*) < \frac{1}{2}r\rnd{C}\).

	Per ogni centroide \(c_i \in C\), consideriamone la sfera di raggio \(\frac{1}{2} r(C)\) attorno. All'interno di ogni sfera esiste esattamente un \(c_i^* \in C^*\), che possiamo considerare accoppiato con \(c_i\).

	Prendiamo ora in considerazione un punto \(s\) qualsiasi ed il suo centroide ottimale più vicino, \(c_i^*\). Vale che:
	\[
		\text{distanza}(s, C) \leq \text{distanza}(s, c_i) \underbrace{\leq}_{\text{dis. triangolare}} \underbrace{\text{distanza}(s, c_i^*) + \text{distanza}(c_i, c_i^*)}_{\leq r(C^*) \text{ dato che \(c_i^*\) è il centroide più vicino.}} \leq 2r(C^*)
	\]
	Ne segue che \(r(C) \leq 2r\rnd{C^*}\).
\end{proof}
\begin{theorem}
	Un algoritmo greedy è una \textit{\(2\)-approximation} per il problema della scelta dei centroidi.
\end{theorem}
\begin{theorem}
	A meno che \textbf{P=NP}, non esiste nessuna \textit{\(\rho\)-approximation} per la selezione dei centroidi che abbia \(\rho<2\).
\end{theorem}
\begin{proof}
	Procediamo per assurdo assumendo che esista una \textit{\(2-\epsilon\)-approximation} con cui possiamo risolvere in tempo polinomiale il set dei punti \(S\).

	Sia \(G = \rnd{V, E}, k \in \N \) un'istanza di \(S\). Procediamo a costruire un'istanza \(G'\) del problema, con \(V\) punti e distanze pari a:
	\[
		\begin{cases}
			\text{distanza}(u,v) = 1 & \text{se \(u, v \in E\)}     \\
			\text{distanza}(u,v) = 2 & \text{se \(u, v \not\in E\)}
		\end{cases}
	\]
	L'istanza così costruita rispetta la disuguaglianza triangolare.

	\(G\) possiede un insieme dominante di dimensione \(k\) se e solo se esistono \(k\) centroidi \(C^*\) con \(r\rnd{C^*} = 1\).

	Ne segue che se \(G\) ha un insieme dominante di dimensione \(k\), un algoritmo con \textit{\(2-\epsilon\)-approximation} troverebbe una soluzione \(C^*\) con \(r(C^*) = 1\), dato che può utilizzare nessun arco a distanza \(2\).

	TODO!!!!! CHIEDI A PROFESSORE DOVE SI INTENDE \(G\) E DOVE SI INTENDE \(G'\)!!!
\end{proof}


\end{document}