\providecommand{\main}{..}
\documentclass[\main/main.tex]{subfiles}
\begin{document}

\section{Mixing time}
\begin{definition}[Mixing time]
  Per ogni \(i \in S\) ed ogni \(n \in \N \) sia \(\matr{P}^n_i\) la \(i\)-esima riga di \(\matr{P}^n\). Definiamo allora:
  \[
    \Delta_{i}(n) = d_{TV}\rnd{\matr{P}^n_i, \pi} \qquad \Delta(n) = \max\crl{\Delta_{i}(n): i \in S}
  \]
  Inoltre, \(\forall \epsilon > 0\) definiamo la funzione \textbf{mixing time} della catena come:
  \[
    \tau(\epsilon) = \min\crl{n \in \N: \Delta(n) \leq \epsilon}
  \]
  Essa rappresenta la miglior funzione che garantisce un'approssimazione alla distribuzione stazionaria con errore al più \(\epsilon\).
\end{definition}

\section{Accoppiamento}
\begin{definition}[Accoppiamento]
  Dato un insieme finito di stati \(S\) e una matrice \textbf{stocastica} \(\matr{P}\), un \textbf{accoppiamento} è una catena di Markov \(\crl{Z_n}\) sull'insieme degli stati \(S\times S\), tale che \(Z_n = \rnd{X_n, Y_n}\) per ogni \(n \in \N \) e \(\forall i,j,l \in S\):
  \begin{align*}
    \prob{X_{n+1} = j}{X_n=i, Y_n=l} & = p_{ij} \\
    \prob{Y_{n+1} = j}{X_n=l, Y_n=i} & = p_{ij}
  \end{align*}
  Le due variabili possono essere viste come due catene \(\crl{X_n}, \crl{Y_n}\) che si muovono in parallelo ad ogni passo.
\end{definition}

\section{Generatore di indipendent set di dimensione fissata}
Consideriamo un grafo non orientato \(G = \rnd{V, E}\) di \(n\) nodi, con grado massimo \(\Delta \) e sia \(k \in \N \) un intero tale che:
\[
  k \leq \frac{n}{3(\Delta + 1)}
\]
Denotiamo l'insieme degli indipendent set di \(G\) di dimensione \(k\) con:
\[
  S_k = \crl{\left. A \subseteq V \right\rvert \#A = k, \forall u, v \in A, \,\crl{u, v} \not\in E }
\]
Sia inoltre \(Z_k(G)\) la cardinalità di \(S_k\). Vogliamo generare un elemento \(A \in S_k\) con probabilità uniforme:
\[
  \pi(A) = \frac{1}{Z_k{G}}
\]
È sempre possibile costruire un elemento \(A \in S_k\) in \(\O{n^2}\) passi.

\subsection{La procedura}
Si sceglie a caso e uniformemente un elemento \(v \in A\) e un elemento\(w \in V\)m quindi se \(w \not\in A \, \land \, (A\setminus \crl{v}) \cup \crl{w} \in S_k\) allora lo stato successivo è definito come \(B = (A\setminus \crl{v}) \cup \crl{w}\).

\subsection{La catena}
Quindi, per ogni \(A, B \in S_k\) la probabilità di transizione è data da:
\[
  P_{AB} = \begin{cases}
    0                                                                                         & \#\crl{\frac{A \cup B}{A \cap B}} > 2 \\
    \frac{1}{kn}                                                                              & \#\crl{\frac{A \cup B}{A \cap B}} = 2 \\
    1 - \frac{\#\crl{\left. C \in S_k \right\rvert \#\crl{\frac{A \cup C}{A \cap C}} = 1}}{k} & A = B
  \end{cases}
\]
La matrice così definita è \textbf{primitiva} e la distribuzione uniforme \(\bm{\pi} \) coincide con la \textbf{distribuzione stazionaria} della catena.

\clearpage
\section{Velocità di convergenza della colorazione di grafi}
Consideriamo una versione ciclica del campionatore di Gibbs per le \(q\)-colorazioni, cioè nella quale tutti i nodi vengono ricolorati dopo un numero fissato di passi.

Dato un grafo non orientato \(G = \rnd{V, E}\) di \(k\) nodi \(V = \crl{v_1, v_2, \ldots, v_k}\) e un insieme di colori \(Q = \crl{1, 2, \ldots, q}\) e un insieme di colorazioni \(Q = \crl{1, 2, \ldots, q}\). Sia \(S\) l'insieme delle \(q\)-colorazioni di \(G\) e sia \(Z_{G, q}\) il loro numero.

Sia infine \(d\) il grado di \(G\), cioè il massimo tra i gradi dei suoi nodi. Supponiamo che il numero dei colori sia abbastanza grande, per esempio \(q>d\): in questo modo siamo sicuro che sia facile determinare una \(q\)-colorazione di \(G\).

\subsection{La procedura}
La procedura definisce una catena di Markov \textbf{non omogenea} \(\crl{X_n}\). Al primo passo si sceglie un elemento \(\crl{X_0}\) qualsiasi, quindi si eseguono \(n\) passi nella catena. All'\(i\)-esimo passo si ricolora il nodo \(v_j\) dove \(j=1+\sqr{i-1}_k\), scegliendo il nuovo colore in modo uniforme sull'insieme dei colori compatibili con quelli dei nodi adiacenti a \(v_j\).

\subsection{Velocità di convergenza}
\begin{theorem}[Velocità di convergenza]
  Dato un insieme di colori \(Q = \crl{1, 2, \ldots, q}\), sia \(G = \rnd{V, E}\) un grafo non orientato di \(k\) nodi, sia \(d\) il grado di \(G\) e sia \(\crl{X_n}\) la catena di Markov descritta sopra sulle \(q\)-colorazioni di \(G\). Denotiamo inoltre con \(\mu^{(n)}\) la distribuzione di probabilità di \(X_n\) e con \(\bm{\pi} \) la distribuzione uniforme sull'insieme delle \(q\)-colorazioni di \(G\).

  Se \(q>2d^2\), allora esiste una costante \(C>0\) dipendente solo da \(d\) e \(q\) tale che per ogni \(\epsilon> 0\) vale:
  \[
    d_{TV}(\mu^{(n)}, \pi) \leq \epsilon
  \]
  per tutti gli \(n \in \N \) che soddisfano:
  \[
    n > Ck\rnd{\log k + \log \frac{1}{\epsilon}}
  \]
\end{theorem}

\end{document}