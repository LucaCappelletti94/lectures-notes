\chapter{Complessità Computazionale e Deduzione Automatica}

In questo momento, per decidere se una formula $F \in \mathscr{F}_\mathscr{L}$ che menziona $n$ lettere proposizionali diverse sia soddisfacibile o meno, l'algoritmo che conosciamo computa la sua tabella di verità, analizzando quindi $2^n$ possibilità, ossia un numero esponenziale. 
qui
Cominciamo definendo cosa sia un problema di decisione:
\begin{defi}[Problema di Decisione]
Dato $\Sigma^*$ un insieme di tutte le \textit{parole} finite costruite coi simboli di $\Sigma$—un \textit{alfabeto} finito—e un \textit{Linguaggio} $L \subseteq \Sigma^*$, non necessariamente finito, il problema di decisione consiste nel verificare se una stringa finita $w$ appartenga o meno al Linguaggio $L$
\end{defi}

Ad esempio, fissato 
$$
\Sigma = \{\land, \lor, \neg, \rightarrow, (, ), p, |\}
$$
si possono definire alcuni problemi, per esempio
$$
\mathscr{F}_\mathscr{L} \subseteq \Sigma ^*
$$
dove il problema risiede nel capire se una certa formula di lunghezza finita
risiede in $\mathscr{F}_\mathscr{L}$ oppure no. 
Vi sono dei problemi principalmente di natura sintattica, come appunto $\mathscr{F}_\mathscr{L}$ 
ma anche $NNF$, $CNF$ e $DNF$. Vi sono problemi in cui la natura semantica 
è decisiva, per esempio $SAT$, dove 
$$
w \in \Sigma^* : w\in SAT \iff w \in \mathscr{F}_\mathscr{L} \land w \text{ è soddisfacibile}
$$
oppure $TAUTO$, dove una stringa finita appartiene a $TAUTO$ sse è una formula ed è una tautologia, ossia
$$
w \in \Sigma^* : w \in TAUTO \iff w \in \mathscr{F}_\mathscr{L} \land \models w
$$
e analogamente $UNSAT$, il problema di decidere se una certa formula è
insoddisfacibile.

\section{Complessità Computazionale}
\subsection{Efficienza}
Alcuni dei problemi elencati precedentemente possono essere risolti (decisi) 
in maniera efficiente, ossia data una \textit{parola} $w$ decidere se 
appartiene ad un certo linguaggio: esempi di soluzioni efficienti sono 
quelle che riguardano tutti i problemi sintattici, risolvibili in tempo 
al massimo quadratico e in realta anche lineare con alcune tecniche di parsing. 

I problemi che riguardano la semantica, invece, sono tipicamente più complessi
da risolvere e infatti, per quanto conosciamo fino ad ora, si possono risolvere 
solo (nel caso peggiore) con un analisi dell'intera tabella di verità della 
formula, quindi con un numero esponenziale di calcoli. \`E importante rimarcare 
nuovamente che benché sussista questa difficoltà, verificare che 
un singolo assegnamento verifichi la formula è invece un calcolo semplice 
che richiede un tempo decisamente più contenuto rispetto al problema di 
decidibilità.

Quindi, vi sono dei problemi decidibili efficientemente, 
dei problemi decidibili molto difficilmente e verificabili facilmente 
e dei problemi decidibili molto difficilmente e verificabili difficilmente; 
da qui parte una gerarchia di classi di complessità infinita, ma a noi interesseranno 
solo le prime due. 
 
Per essere più precisi, si fissa un modello astratto di computazione, che fornisca 
la nozione di \textit{passo elementare}, in modo da poter ragionare precisamente 
sull'efficienza dei problemi. 
Qualunque modello di computazione che costituisca un modello realistico 
di calcolatore, con associata una nozione di passo elementare per costruire 
algoritmi, classifica i problemi nello stesso modo. 

\begin{oss}[Tesi di Church-Turing]
  Ogni modello ragionevole di computazione è equivalente.
\end{oss}

Uno dei modelli di computazione è quello delle Macchine di Turing (MdT): un'idea 
della Macchina di Turing è immaginarla come una macchina che lavora su un 
nastro infinito in lettura e scrittura, mantenendo uno stato e operando su 
una singola porzione di nastro in lettura utilizzando un programma per 
muoversi tra gli stati e scrivere sul nastro. 

Si può passare ora alla definizione formale delle classi dei problemi: 
\begin{defi}[Classe $\mathbb{P}$]
  La classe dei problemi ``efficientemente decidibili'' è definita, con una 
  certa ideologia sottesa, come tutti quei problemi che possono essere 
  risolti in tempo polinomiale, ossia esiste una certa Macchina di Turing T 
  e un polinomio $p: \mathbb{N}\rightarrow \mathbb{N}$ per i quali per ogni 
  $w \in \Sigma^*$  la computazione della MdT sull'input $w$, 
  denotato $T(w)$ termina entro $p(||w||)$ passi e per ogni $w \in L$ si 
  ha che $T(w)$ accetta il problema e per ogni $w \notin L$  si ha 
  che $T(w)$ non accetta, ossia risolve il problema.
\end{defi}

\begin{defi}[Classe $\mathbb{NP}$]
  La classe dei problemi ``verificabili efficientemente'' è definita come 
  tutti quei problemi tali per cui esiste una Macchina di Turing deterministica 
  e due polinomi $p,q:\mathbb{N}\rightarrow \mathbb{N}$ tali che per ogni 
  $w \in \Sigma^*$ e ogni $z \in \Gamma^*$, ossia un \textbf{certificato}, 
  che si può immaginare prodotto da un oracolo, si ha 
  che $T(w,z)$ termina entro $p(||w||)$ passi e si ha che per ogni 
  $w \in L$ esiste $z \in \Gamma^*$ tale che $||z|| \leq q(||w||)$ (ossia 
  il certificato è sufficientemente corto) e $T(w,z)$ accetta e per ogni 
  $w \notin L$ si ha che per ogni possibile $z \in \Gamma^*$ sufficientemente corto
  $T(w,z)$ rifiuta, ossia ``valida'' il certificato.
\end{defi}

\begin{defi}[Riducibilità]
        Un problema $L_1 \subseteq \Sigma^*$ è \textbf{riducibile in tempo polinomiale} 
        a un altro problema $L_2 \subseteq \Gamma^*$ se e solo se esistono
        una Macchina di Turing $T_{{L_1}, {L_2}}$ e un polinomio
        $p: \mathbb{N} \rightarrow \mathbb{N}$ tale che per ogni $w \in L_1$
        $T(w)$ trasfroma $w$ in $w' \in \Gamma^*$ in un numero di passi 
        minore o uguale a $p(||w||)$. 
\end{defi}

Per indicare la relazione di riducibilità tra due problemi si indica la notazione 
$L_1 \preceq_p L_2$ per indicare che il primo problema è riducibile polinomialmente 
al secondo; la nozione di riducibilità è utile poiché rende possibile risolvere 
istanze del problema $L_1$ ``riscrivendole'' come se fossero istanze di $L_2$
(chiaramente questa utilità si verifica quando è più facile risolvere $L_2$ di 
$L_1$). 
Un esempio di riducibilità polinomiale è 
$$
TAUTO \preceq_p UNSAT
$$
poiché la trasformazione $w \rightarrow \neg w$ è semplice e si sa che 
$w$ è tautologica se e solo se $\neg w$ è insoddisfacibile.

\begin{defi}[Problemi $\mathbb{NP}$-completi]
        Un problema appartenente alla classe $\mathbb{NP}_c$ è un problema 
        $L \subseteq \Sigma^*$ se e solo se 
        \begin{itemize}
                \item $L \in \mathbb{NP}$
                \item ogni $L' \in \mathbb{NP}$ è tale che $L' \preceq_p L$ 
        \end{itemize}
        La seconda proprietà si chiama $\mathbb{NP}$-hardness. 
\end{defi}
Come corollario della definizione dei problemi $\mathbb{NP}_c$, si ha che risolvendo 
polinomialmente un problema di tale classe si dimostra che 
$$
\mathbb{P} = \mathbb{NP}
$$

\begin{teo}[di Cook-Levin]
        $CNFSAT \in \mathbb{NP}$-completo.
        ($\implies SAT \in \mathbb{NP}$-completo)
\end{teo}

$CNFSAT \preceq_p SAT$ è vero perché una formula in CNF è comunque ancora una formula e pertanto la trasformazione—i.e., la funzione identità—è ovviamente polinomiale.\\
Si mostra ora che $SAT \preceq_p CNFSAT$, conservando non l'equivalenza logica ma la \textit{relazione di equisoddisfacibilità}.
Questo ci permetterà anche di trasformare polinomialmente le $DNF$ in $CNF$ equisoddisfacibili. Infattibile se si cercasse di mantenere l'$\equiv$.

\subsection{Equisoddisfacibilità}
\begin{defi}[Equisoddisfacibilità]
Siano $A, B \in \mathscr{F}_\mathscr{L}$. $A$ e $B$ sono equisoddisfacibili ($equisodd$) sse:
$$
A\ sodd. \iff B\ sodd.
$$
ossia se $A$ e $B$ sono entrambe soddisfsacibili o entrambe insoddisfacibili. 
\end{defi}

\subsubsection{Osservazioni sull'equisoddisfacibilità}
\begin{ossn}
L'equivalenza implica l'equisoddisfacibilità, ma non è vero il contrario.
\begin{enumerate}
\item Date le due formule $\neg (A \land B)$ e $\neg A \lor \neg B$, è noto 
che sono equivalenti grazie alle leggi di De Morgan e sono, di conseguenza, 
anche equisoddisfacibili.
\item $\neg (A \land B)$ e $(\neg A \land \neg B)$ non sono equivalenti, 
infatti l'assegnamento $A=1$ e $B=1$ soddisfa solo una delle due, tuttavia 
sono equisoddisfacibili.
\item $A \land \neg A$ e $\neg A \land \neg B$ non sono né equivalenti né
equisoddisfacibili.
\end{enumerate}
\end{ossn}

\begin{ossn}
$equisodd.$ è un tipo di relazione d'equivalenza:
\begin{itemize}
  \item $A\ equisodd.\ A$
  \item $A\ equisodd.\ B$, quindi $B\ equisodd.\ A$
  \item $A\ equisodd.\ B$ e $B\ equisodd.\ C$, quindi $A\ equisodd.\ C$
\end{itemize}
\end{ossn}

\begin{ossn}
$equisodd.$ non è una congruenza rispetto ai connettivi, pensati come operazioni. \\
Per esempio, rispetto a $\neg$: \\
se $A\ equisodd. B$ con $\models A$ e $\nvDash B$ (i.e. $B$ non è tautologica), allora vuol dire che $\neg A$ \textbf{non} è $equisodd.$ con $\neg B$—perché $A \in \bot$ ma $B$ potrebbe essere soddisfacibile.
\end{ossn}

\begin{ossn} $equisodd.$ è più grezza di $\equiv$, infatti le classi di equivalenza delle formule su $n$ variabili $\mathscr{F}_\mathscr{L}^{(n)}/\equiv$, sono $2^{2^n}$. \\
L'equisoddisfacibilità, invece, ha unicamente due classi: l'insieme delle formule insoddisfacibili ($[\bot]$) e tutte le rimanenti, ossia tutte quelle soddisfacibili da almeno un assegnamento.
\end{ossn}
Quest'ultima osservazione era deducibile anche dalla Osservazione 1.

\subsection{Riduzione $SAT \preceq CNFSAT$}
Sia $A \in \mathscr{F}_\mathscr{L}$ tale che $A$ sia in Negation Normal Form, ossia $A \in NNF$. \\
Se $A \notin CNF$, allora contiene almeno una violazione, ovvero una sottoformula del tipo $C \lor (D_1 \land D_2)$ oppure $(D_1 \land D_2) \lor C$ (c'è un $\land$ interno ad un $\lor$).

Senza perdita di generalità trattiamo, d'ora in poi, solo il primo dei due casi. Sia $A \in NNF$, ogni sua violazione $B = C \lor (D_1 \land D_2)$ si sostituisce con una nuova lettera proposizionale $a \in L$ che ancora non è presente in $A$. Si crea quindi $B'$ tale che:
\begin{align*}
B' := B'' \land (\neg a \lor D_1) \land (\neg a \lor D_2)
&&
\text{con } B'' := B[a/D_1\land D_2]
\end{align*}

Si osservi che $(\neg a \lor D_1) \land (\neg a \lor D_2) \equiv a \rightarrow (D_1 \land D_2)$. \\
\begin{lem}
$B'$ e $B$ sono equisoddisfacibili, ma in genere non sono equivalenti.\\
E $B'$ ha $2n + 1$ clausole, di cui $1$ di $n$ letterali e $2n$ di $2$ letterali .
\end{lem}
\begin{proof}[Dimostrazione $B \in SAT \implies B' \in SAT$]
        Per ipotesi, dato che $B$ è soddisfacibile, sia $\mathcal{v}:\mathscr{L} \rightarrow \{0,1\}$
        tale che $\mathcal{v}(B) = 1$, ossia $\mathcal{v} \models B$. 
        Si definisce 
        $$
        \mathcal{v}_a: \mathscr{L} \rightarrow \{0,1\} = 
        \begin{cases}
                \mathcal{v}_a(p) = \mathcal{v}(p) & \forall p \in L, p \neq a \\
                \mathcal{v}_a(a) = \mathcal{v}(D_1 \land D_2) 
        \end{cases} 
        $$
        L'assegnamento $\mathcal{v}_a$ è ben definito, nel senso che non 
        da alla stessa lettera proposizionale due assegnamenti diversi.
        Si nota che $\mathcal{v}_a \models a \rightarrow (D_1 \land D_2)$, 
        dato che per definizione $\mathcal{v}_a(a) = \mathcal{v}(D_1 \land D_2)$
        e per interpretazione dell'implicazione $0 \rightarrow 0 = 1$ e 
        $1 \rightarrow 1 = 1$; dunque:
        \begin{align}
        \label{dim:b'-equiv-b''}
        \mathcal{v}_a(B') = \mathcal{v}_a(B'' \land a \rightarrow (D_1 \land D_2)) = \mathcal{v}_a(B'') \land 1 = \mathcal{v}_a(B'')
        \end{align}
        $B$ e $B''$ si possono riscrivere come: 
        \begin{align*}
        B & = B''[D_1 \land D_2/a] & \text{dato che } a \text{ non appare in } B \\
        B'' & = B''[a/a]
        \end{align*}
        e grazie al Lemma~\ref{lem:sostituzione} di Sostituzione si può affermare che $\mathcal{v}_a(B) = \mathcal{v}_a(B'')$ in quanto $\mathcal{v}_a(a) = \mathcal{v}_a(D_1 \land D_2)$. \\
        Quindi:
        \begin{align*}
                1 &= \mathcal{v}(B) & \text{ipotesi } \\
                  &= \mathcal{v}_a(B) & a \text{ non occore in } B \\
                  &= \mathcal{v}_a(B'') & \text{per il Lemma di Sost.}  \\
                  &= \mathcal{v}_a(B') & \text{per~\ref{dim:b'-equiv-b''}}
        \end{align*}
        ossia l'assegnamento che soddisfa $B$ soddisfa anche $B'$, ossia 
        sono equisoddisfacibili. 
\end{proof}
\begin{proof}[Dimostrazione $B' \in SAT \implies B \in SAT$]
        Se $B'$ è soddisfacibile da un assegnamento della forma $\mathcal{v}_a$—ossia tale che $\mathcal{v}_a(a) = \mathcal{v}(D_1 \land D_2)$—allora si può tranquillamente ribaltare la catena di uguaglianze precedente: 
        \begin{align*}
          \mathcal{v}_a \models B' \text{ sse }1 &= \mathcal{v}_a(B') \\
          &= \mathcal{v}_a(B'') & \text{per~\ref{dim:b'-equiv-b''}}  \\
          &= \mathcal{v}_a(B) & \text{per il Lemma di Sost.} \\
          \text{sse } & \mathcal{v}_a \models B
        \end{align*}
        Si supponga, ora, che $B'$ sia soddisfatto solo da assegnamenti $\mathcal{w}$ che non sono della forma $\mathcal{v}_a$, ossia $\mathcal{w}(a) \neq \mathcal{w}(D_1 \land D_2)$. Vi sono allora due casi:
        \begin{itemize}
          \item $\mathcal{w}(a) = 0 \neq \mathcal{w}(D_1 \land D_2) = 1$
          \item $\mathcal{w}(a) = 1 \neq \mathcal{w}(D_1 \land D_2) = 0$
        \end{itemize}
        Tuttavia quest'ultimo caso è impossibile, poiché $\mathcal{w}(a \rightarrow D_1 \land D_2) = 1 \rightarrow 0 = 0 = \mathcal{w}(B')$ e quindi $\mathcal{w}$ non soddisferebbe $B'$.
        
        Quindi rimane il primo caso e bisogna mostrare che effettivamente soddisfa $B'$ e non porta ad un assurdo
        
        \begin{oss}
        Sia $E$ un'espressione formata solo da $0, 1, \land, \lor$—interpretabili come $\min$ e $\max$. Il valore di $E$, quindi, è o $0$ o $1$. \\
        Sia $E'$ ottenuta da $E$ rimpiazzando nessuna o più occorrenze  del simbolo $0$ con $1$. \\
        Allora $E \leq E'$.
        
        Questo perché $0, 1, \min, \max$ sono tutte funzioni non decrescenti, e $E$ ed $E'$ sono composizioni di funzioni non decrescenti, pertanto sono non decrescenti neanche loro. \\
        (un'altra prova è per induzione strutturale su $E$).
        \end{oss}

        Ora, tornando al problema principale, si ha che:
        \begin{align*}
        \mathcal{w}(B') = 1 &&
        \mathcal{w}(a) = 0 &&
        \mathcal{w}(D_1 \land D_2) = 1
        \end{align*}
        Se $Var(B) = \{p_1,\cdots p_n\}$, allora $\mathcal{w}(B)$ e $\mathcal{w}(B'')$ si possono esprimere come funzioni termine di $B''$:
        \begin{align*}
        \mathcal{w}(B'') & = \hat{B}''(\mathcal{w}(p_1), \cdots, \mathcal{w}(p_n), \mathcal{w}(a)) \\
        \mathcal{w}(B) & = \hat{B}''(\mathcal{w}(p_1), \cdots, \mathcal{w}(p_n), \mathcal{w}(D_1 \land D_2)) & \text{per def. } B''
        \end{align*}
        Dato che la formula iniziale $A$ era in $NNF$, anche $B''$, $B'$ e $B$ lo sono, e $\mathcal{w}(B'')$ e $\mathcal{w}(B)$ sono quindi considerabili come espressioni costruite su $0,1,\land,\lor$, per l'osservazione precedente. \\
        Si può concludere, quindi, che
        $$
        \mathcal{w}(B'') = \hat{B}''(\mathcal{w}(p_1), \cdots, \mathcal{w}(p_n), 0) \leq \hat{B}''(\mathcal{w}(p_1), \cdots, \mathcal{w}(p_n), 1) = \mathcal{w}(B)
        $$
        ma $\mathcal{w}(B'') = 1$, quindi $\mathcal{w}(B) = 1$ 
\end{proof}

\begin{oss}[Nota finale]
        Si sarebbe potuto definire $B'$, alternativamente, come segue: 
        \begin{align*}
                B' :&= B[a/D_1 \land D_2] \land (a \leftrightarrow (D_1 \land D_2))^c \\
                   &=  B[a/D_1 \land D_2] \land (\neg a \lor D_1) \land (\neg a \lor D_2) \land ((D_1 \land D_2) \rightarrow a)^c \\
                   &=  B[a/D_1 \land D_2] \land (\neg a \lor D_1) \land (\neg a \lor D_2) \land (a \lor \neg D_1 \lor \neg D_2)
        \end{align*}
        Nella prova di $B' \in SAT \implies B \in SAT$ si sarebbe potuto mostrare che $B'$ è soddisfatto solo da assegnamenti nella forma di $\mathcal{v}_a$ tali che $\mathcal{v}_a(a) = \mathcal{v}(D_1\land D_2)$.
\end{oss}

\paragraph{Dilatazione della riduzione $NNF$-$CNF$}
Nel passaggio da $B$ a $B'$ si osserva una dilatazione nella lunghezza della formula, ossia $B'$ è \textit{più lungo} di $B$; data la formula 
generale 
$$
B' := B[a/D_1 \land D_2] \land (\neg a \lor D_1) \land (\neg a \lor D_2)
$$
La parte che subisce la sostituzione può essersi accorciata, a cui però si aggiungono una decina di simboli. Quindi $||B'|| \leq ||B|| + k$, con $k$ una costante dipendente dal modo in cui si conta la lunghezza (si contano le parentesi come simboli eccetera). \\
Per ogni ``violazione'' $B$ nella formula originale $A$, la formula risultante equisoddisfacibile senza violazioni è più lunga di $k \cdot v$ caratteri, con $v =$ \#violazioni. \\
Inoltre, visto che in $A$ non può essere più lunga di $v$, la formula risultante $A'$ avrà lunghezza $||A'|| \leq ||A|| + k \cdot v \leq (k + 1) \cdot ||A||$, una dilatazione \textit{lineare}.

La tecnica usata per ridurre $SAT \preceq_p CNFSAT$ che consiste nel rimpiazzare 
$B$ con $B'$ equisoddisfacibile è ispirata alla riduzione 
$$
SAT \preceq_p 3CNFSAT
$$
dovuta a Karp. Il passaggio $B \implies B'$ è un esempio del cosiddetto 
``Tseytin's Trick'', che si usa per ridurre $F \in \mathscr{F}_\mathscr{L}$ a una 
in $3CNFSAT$ ad essa equisoddisfacibile. 

\begin{defi}[Problemi $3CNFSAT$]
$3CNFSAT \subseteq CNFSAT \subseteq \mathscr{F}_\mathscr{L}$ è costituito da tutte e sole le CNF dove ogni clausola contiene esattamente $3$ letterali. \\
$3CNFSAT \in \mathbb{NP}$-completo.
\end{defi}
\begin{oss}[Problemi $2CNFSAT$]
        $2CNFSAT \in \mathbb{P}$.
\end{oss}
\begin{algorithm}
\caption{Algoritmo di riduzione a CNF equisoddisfacibili}
\begin{algorithmic} 
\REQUIRE $F \in \mathscr{F}_\mathscr{L}$
\ENSURE $A \in CNF : F\ equisodd.\ A$
\STATE {$A : A \in NNF \land A \equiv F$}
\WHILE{$A \notin CNF$}
\STATE $B \leftarrow$ violazione in $A$
\STATE $B' \leftarrow B[a/D_1 \land D_2] \land (\neg a \lor D_1) \land (\neg a \lor D_2)$ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ con $a \notin Var(B)$
\STATE $A \leftarrow A[B/B']$
\ENDWHILE
\RETURN{$A$}
\end{algorithmic}
\end{algorithm}

\subsubsection{Esempi}
\paragraph{1} Sia $A := p \lor (q \land r)$ in $NNF$. Si trasforma ora in una formula equisoddisfacibile in CNF: 
$$
A' := (p \lor a) \land (\neg a \lor q) \land (\neg a \lor r)
$$
Queste due formule non sono equivalenti, infatti vi sono assegnamenti 
che portano a risultati diversi; tuttavia sono equisoddisfacibili.

\paragraph{2} 
Sia $A := (p_1 \land p_2) \lor (p_2 \land q_2) \lor (p_3 \land q_3)$. Applicando iteramente la sostituzione, si ha:
\begin{align*}
(a_1 \lor (p_2 \land q_2) \lor (p_3 \land q_3)) & \land (\neg a_1 \lor p_1) \land (\neg a_1 \lor q_1) \\
(a_1 \lor a_2 \lor (p_3 \land q_3)) & \land (\neg a_1 \lor p_1) \land (\neg a_1 \lor q_1) \land (\neg a_2 \lor p_2) \land (\neg a_2 \lor p_2) \\
(a_1 \lor a_2 \lor a_3) & \land (\neg a_1 \lor p_1) \land (\neg a_1 \lor q_1) \land (\neg a_2 \lor p_2) \land (\neg a_2 \lor q_2) \land (\neg a_3 \lor p_3) \land (\neg a_3 \lor q_3)
\end{align*}
Data una formula con $n$ letterali si generano $2 \cdot n +1 $ clausole, 
di cui una con $n$ letterali e $2n$ con due letterali, laddove utilizzando la 
distributività se ne generavano $2^n$ ognuna con $n$ letterali. 


\section{Deduzione Automatica}
Ricordiamo che noi vorremmo studiare $\Gamma \stackrel{?}{\models} A$, che si può ricondurre ad un problema di soddisfacibilità o al suo complementare di insoddisfacibilità. Tuttavia:
\begin{align*}
  & \mathbb{NP}\text{-complete} \ni SAT \preceq_p CNFSAT \\
  & \text{co}\mathbb{NP}\text{-complete} \ni TAUTO \preceq_p SAT^c \preceq_p CNFUNSAT
\end{align*}

Il motivo per cui non studiamo invece $DNFSAT$ e $DNFUNSAT$—che sono in $\mathbb{P}$—è che $SAT \npreceq_p DNFSAT$. Non c'è un algoritmo per ``tradurre'' una formula arbitraria equisoddisfacibile in $DNF$ in modo che sia sufficientemente corta: i metodi conosciuti allungano esponenzialmente la formula.

\begin{defi}[Variazione notazionale]
Date $F_i \in \mathscr{F}_\mathscr{L}$, le formule 
\begin{align*}
  F_1 \land F_2 \land \cdots \land F_k &&
  F_1 \lor F_2 \lor \cdots \lor F_k
\end{align*}
si possono scrivere senza parentesi grazie all'associatività, si possono scambiare le formule interne nelle formule esterne ($F_1 \land F_2 \equiv F_2 \land F_1$) grazie alla commutatività e, infine, si possono espandere le singole formule ($F_1 \land F_1  \equiv F_1$) grazie all'idempotenza.

Per questo motivo d'ora in poi per le $CNF$ tralasceremo gli operatori $\land$ e $\lor$ in favore di una notazione insiemistica. Per esempio:
\begin{align*}
  (p \lor q \lor \neg r) \land &(q \lor r \lor a) \land p \\
  & \Downarrow \\
  \{ \{p, q, \neg r\}, &\{q, r, a\}, \{p\}\}
\end{align*}
Una teoria costituita da CNF è indicata come l'insieme di tutte le clausole appartenenti a qualche CNF della teoria (di fatto è una CNF più grande). Inoltre:
\begin{align*}
  & \emptyset = CNF \text{ vuota} \\
  & \qedsymbol = \text{ clausola vuota} \\
  & \{\cdots, \qedsymbol, \cdots \} = CNF \text{ contenente la clausola vuota}.
\end{align*}
\end{defi}

Il problema di definire se $A$ è conseguenza logica di una teoria $\Gamma$ 
$$
\Gamma \stackrel{?}{\models} A
$$
si può ridurre a calcolare la insoddisfacibilità di $\Gamma \cup \{\neg A\}$, che è uguale a calcolare l'insoddisfacibilità della sua forma in CNF $S := \{\Gamma^c \cup \{\neg A\}^c\}$ dove $\Gamma^c := \{\gamma^c | \gamma \in \Gamma\}$ e $\{\neg A\}^c \in CNF$. 

Il problema $\Gamma \models A$ è stato ridotto polinomialmente al problema $S \in CNFSAT$,
dove $S$ è un insieme di clausole considerate come insiemi di letterali, 
eventualmente infinito.


\subsection{Metodi refutazionali}
$S$ è soddisfacibile se esiste $\mathcal{v}:\mathscr{L} \rightarrow \{0,1\}$ tale 
che per ogni clausola $C \in S, \mathcal{v} \models C$, in altre parole esiste un letterale $\ell \in C$ tale che $\mathcal{v} \models \ell$. 

Se l'obiettivo è dimostrare che $S$ è insoddisfacibile, una strategia 
può essere ampliare $S$ in un nuovo insieme $S \subseteq S'$ in modo 
tale che $S'$ è logicamente equivalente o almeno equisoddisfacibile a $S$.
Ad esempio, se ampliando iterativamente $S$ in $S'$, $S''$ fino a $S^{(u)}$ 
e alla fine la clausola vuota $\qedsymbol$ appartiene a $S^{(u)}$ allora quest'ultimo 
è insoddisfacibile, e quindi anche $S$ lo è. Questa idea può essere sfruttata 
disegnando \textbf{metodi refutazionali}, ossia metodi che hanno l'obiettivo di 
provare l'insoddisfacibilità di un insieme di clausole, in questo frangente, 
ma più in generale anche di una formula o una teoria. Questi metodi sono basati 
sulla regola di inferenza chiamata \textbf{principio di risoluzione}, 
il quale è utile per un tipo di calcolo particolarmente adatto a essere automatizzato, 
ossia SAT solver e Theorem Prover. 

\begin{defi}[Principio di Risoluzione]
        Date due clausole $C_1$ e $C_2$ si dice che $D$ è la \textbf{risolvente}
        di $C_1$ e $C_2$ sul pivot $\ell$ se e solo se
        \begin{itemize}
                \item $\ell \in C_1$
                \item $\bar{\ell} \in C_2$
                \item $D := (C_1 \setminus \{\ell\}) \cup (C_2 \setminus \{\bar{\ell}\})$
        \end{itemize}
       e si scriverà $D = \mathbb{R}(C_1,C_2; \ell, \bar{\ell})$. 
\end{defi}

\subsubsection{Esercizio}
Mostrare che $(C_1 \setminus \{\ell\}) \cup (C_2 \setminus \{\bar{\ell}\})$ può essere 
diverso da $(C_1 \cup C_2) \setminus \{\ell, \bar{\ell}\}$.

Sia $C_1 = \{a,\neg a\}$ e $C_2 = \{a, \neg a, b\}$. Allora
\begin{align*}
  (C_1 \setminus \{a\}) \cup (C_2 \setminus \{\neg a\}) & = \{a, \neg a, b\} \\
  (C_1 \cup C_2) \setminus \{a, \neg a\} & = \{b\}
\end{align*}
  

\subsubsection{Esempio}
Sia $C_1 := \{x, y, \neg t\}$ e $C_2 := \{u, \neg y, t\}$; si ha
\begin{align*}
D_1 & = \mathbb{R}(C_1, C_2; y, \neg y) = \{x, \neg t, u\} \\
D_2 & = \mathbb{R}(C_1, C_2; \neg t, t) = \{x, y, u, \neg y\}
\end{align*} 

\begin{lemn}[di correttezza della risoluzione]
\label{lem:correttezza-risoluzione}
        Sia $D = \mathbb{R}(C_1, C_2; \ell, \bar{\ell})$, allora 
        $$
        \{C_1, C_2\} \models D
        $$
\end{lemn}

\begin{proof}
Dimostriamo che $\mathcal{v} \models C_1$ e $\mathcal{v} \models C_2 \implies \mathscr{v} \models D$. \\
Sia $\mathcal{v} : \mathscr{L} \rightarrow \{0, 1\}$ tale che:
  \begin{align*}
    & \mathcal{v} \models C_1 \text{ e } \mathcal{v} \models C_2 \\
    \implies & \exists m \in C_1, n \in C_2 \text{ t.c. } \mathcal{v} \models m \text{ e } \mathcal{v} \models n \\
    & \text{Per assurdo assumiamo } m = \ell \text{ e } n = \bar \ell \\
    \implies & \mathcal{v}(\ell) = 1 \text{ e } \mathcal{v}(\bar \ell) =1 \\
    \implies & \bot \\
    \implies & m \neq \ell \text{ o } n \neq \bar \ell \\
    \implies &  m \in D \text{ o } n \in D \\
    \implies & \mathcal{v}(D) = 1
  \end{align*}
\end{proof}

\begin{cor}
        Se $\mathbb{R}(C_1, C_2; \ell, \bar{\ell}) = \qedsymbol$ allora 
        $\{C_1, C_2\}$ è insoddisfacibile, in quanto $\{C_1, C_2\} \models \qedsymbol$.
\end{cor}
\begin{defi}[\textit{Calcolo refutazionale basato su risoluzione}]
  Sia $S$ un insieme di clausole e sia $S := S_0, S_1, \cdots, S_k$ una successione di insiemi tale che per ogni $i = 0, \cdots, k-1$ si ha che $S_{i+1}$ si ottiene unendo a $S_i$ una o più risolventi di clausole in $S_i$. \\
  Se $\qedsymbol \in S_k$, allora $S$ è insoddisfacibile.
\end{defi}
L'obiettivo è mostrare che i calcoli refutazionali basati su applicazioni 
ripetute della risoluzione sono corretti e completi (refutazionalmente).
In genere, per un calcolo logico si studiano infatti le due
seguenti proprietà:
\begin{defi}[Correttezza]
        Un calcolo si definisce \textbf{corretto} se i certificati che produce 
        testimoniano il vero, ossia sono corretti, in altre parole 
        non produce certificati fasulli. 
\end{defi}

Per esempio, nel frangente attuale $S_0, S_1, \cdots, S_k \ni \qedsymbol$ è un certificato corretto dell'insoddisfacibilità di $S = S_0$. \\
Questo genere di calcolo è corretto, e la dimostrazione scende direttamente dal Lemma~\ref{lem:correttezza-risoluzione}, come vedremo tra poco.

\begin{defi}[Completezza]
        Un calcolo è completo se non omette alcun certificato. 
\end{defi}
Nella situazione attuale vuol dire che se $S$ è insoddisfacibile, allora esiste $S_0, S_1, \cdots, S_k$ tale che si produce $\qedsymbol \in S_k$.

Prima di mostrare che il calcolo refutazionale è completo, è necessario 
prepararsi la strada, poiché non sarà banale. 

\begin{teo}[Teorema di Completezza del principio di risoluzione (o di Robinson)]
Un insieme $S$ di clausole è insoddisfacibile $\iff \qedsymbol \in \mathscr{R}^*(S)$, dove $\mathscr{R}^*(S)$ è definito come segue:
\begin{align*}
  \mathscr{R}^0(S) &:= S \\
  \mathscr{R}^1(S) &:= S \cup \{D: D = \mathbb{R}(C_1, C_2; \ell, \bar{\ell})\} & \text{per qualche } C_1,C_2 \in S \text{ e } \ell \in C_1 \text{ e } \bar\ell \in C_2 \\
  \mathscr{R}^2(S) &:= \mathscr{R}(\mathscr{R}(S)) \\
  \cdots \\
  \mathscr{R}^{t+1}(S) &:= \mathscr{R}(\mathscr{R}^{t}(S)) \\
  \cdots \\
  \mathscr{R}^*(S) &:= \bigcup\limits_{i \in \omega} \mathscr{R}^i(S)
\end{align*} 
\end{teo}

Il calcolo $\mathscr{R}^*$ è un metodo \textit{a forza bruta}, applica il Principio di Risoluzione calcolando ciecamente tutte le risoluzioni possibili. Per questo non c'è da sperare che faccia molto meglio delle tavole di verità. 

\begin{proof}
\textit{Correttezza del calcolo $\mathscr{R}$: $\qedsymbol \in \mathscr{R}^*(S) \implies S$ insoddisfacibile} \\
\begin{align*}
& \qedsymbol \in \mathscr{R}^*(S) \\
\iff & \exists i \in \omega : \qedsymbol \in \mathscr{R}^i(S) & \text{per def. } \mathscr{R}^*(S) \\
\iff & \mathscr{R}^i(S)\ insodd. & \text{per def. di clausola vuota} \\
\iff & \mathscr{R}^i(S) \equiv \mathscr{R}^{i-1}(S) \equiv \cdots \equiv \mathscr{R}^0(S) = S & \text{per Lemma~\ref{lem:correttezza-risoluzione}} \\
\iff & S\ insodd.
\end{align*}
\end{proof}

\begin{proof}
\textit{Completezza Refutazionale del calcolo $\mathscr{R}$: $S \text{ insodd. } \implies \qedsymbol \in \mathscr{R}^*(S)$} \\
Dato che $S$ è insoddisfacibile, per il Teorema~\ref{thm:compattezza-prop} di Compattezza esiste un $S_{fin} \subseteq_{\omega} S$ finito e $S_{fin}$ è insoddisfacibile; 
bisogna capire come sia fatto $S_{fin}$: l'insieme finito $S_{fin}$ contiene un numero finito di lettere proposizionali $Var(S_{fin}) \subseteq \{p_1, p_2, \cdots, p_n\}$ per qualche $n \in  \omega$, $p_i \in \mathscr{L}$. \\
La notazione $C^{n}_\mathscr{L}$ indica l'insieme di tutte le clausole scrivibili sulle prime $n$ lettere proposizionali.
\begin{oss}
$S_{fin} \subseteq C^{n}_\mathscr{L}$ e $C^{0}_\mathscr{L} = \{ \qedsymbol \}$
\end{oss}
\textit{A fortiori}: dato che $S_{fin} \subseteq C^{n}_\mathscr{L}$, si ha $S_{fin} \subseteq (C^{n}_\mathscr{L} \cap S) \subseteq (C_\mathscr{L}^{n} \cap \mathscr{R}^*(S))$ e pertanto $C^{n}_\mathscr{L} \cap \mathscr{R}^*(S)$ è insodd., dato che $S_{fin}$ è insodd. \\
Dimostreremo, quindi, che $C^k_\mathscr{L} \cap \mathscr{R}^*(S) \text{ è insodd.}$ per ogni $ k = n, \cdots, 1,0$. Compreso, per $k = 0$:
$$
C^{0}_\mathscr{L} \cap \mathscr{R}^*(S) \text{ insodd. }
$$
Tuttavia dobbiamo capire com'è fatto $C^0_\mathscr{L} \cap \mathscr{R}^*(S)$:
$$
C^{0}_\mathscr{L} \cap \mathscr{R}^*(S) = 
\begin{cases}
  \emptyset  & \leadsto C^0_\mathscr{L} \cap \mathscr{R}^*(S) \text{ sodd. } \leadsto \bot \\
  \{\qedsymbol\} & \leadsto \text{ unico caso possibile }
\end{cases}
$$
Ma quindi, per def. di $\cap$, $\qedsymbol \in \mathscr{R}^*(S)$!

Per dimostrare che per ogni $k = n, \cdots, 1, 0$ 
$$
C^k_\mathscr{L} \cap \mathscr{R}^*(S) \text{ è insoddisfacibile} 
$$
si usa l'induzione decrescente su $k$:
\begin{itemize}
\item \textbf{base} ($k = n$): $C^n_\mathscr{L} \cap \mathscr{R}^*(S)$ insodd. (già dimostrato)
\item \textbf{passo} ($k-1$): si assume l'asserto vero per $n, n-1, \cdots, k$ e si dimostra per $k-1$, ossia 
$$
C^n_\mathscr{L} \cap \mathscr{R}^*(S), C^{n-1}_\mathscr{L} \cap \mathscr{R}^*(S), \cdots, C^k_\mathscr{L} \cap \mathscr{R}^*(S) \text{  insodd.}
$$

Per assurdo, si assuma $C^{k-1}_\mathscr{L} \cap \mathscr{R}^*(S)$ sodd., dunque esiste $\mathcal{v} \models C$ per ogni $C \in C^k_\mathscr{L} \cap \mathscr{R}^*(S)$; si definiscono ora 
\begin{align*}
\mathcal{v}^+ : \mathscr{L} \rightarrow \{0,1\},\ \mathcal{v}^+(p_k) = 1 \\
\mathcal{v}^- : \mathscr{L} \rightarrow \{0,1\},\ \mathcal{v}^-(p_k) = 0
\end{align*}
mentre per ogni altra $p_i \in C^k_\mathscr{L}$, $\mathcal{v}(p_i) = \mathcal{v}^+(p_i) = \mathcal{v}^-(p_i)$; si noti che $p_k \notin C^{k-1}_\mathscr{L}$. 
Per ipotesi induttiva esistono $C_1, C_2 \in C^k_\mathscr{L} \cap \mathscr{R}^*(S)$ insoddisfacibili, tali che:
\begin{align*}
\mathcal{v}^+(C_1) = 0 && \mathcal{v}^-(C_2) = 0
\end{align*}
La lettera proposizionale $p_k$ occorre in $C_1$, altrimenti vorrebbe dire che $C_1 \in C^{k-1}_\mathscr{L} \cap \mathscr{R}^*(S)$ e, visto che $C^{k-1}_\mathscr{L} \cap \mathscr{R}^*(S)$ è sodd. per ipotesi assurda, vorrebbe dire che $\mathcal{v}^+(C_1) = \mathcal{v}(C_1) = 1$. Assurdo. \\
Deve però apparire come letterale $\neg p_k$, così che $\mathcal{v}^+(C_1) = 0$ come da ipotesi. \\
Analogamente, $p_k$ occorre in $C_2$ e più precisamente come letterale positivo $p_k$ e la prova è identica, \textit{mutantis mutandis}. 

Dunque, esiste $D = \mathbb{R}(C_1, C_2; \neg p_k, p_k) = (C_1 \setminus \{ \neg p_k\}) \cup (C_2 \setminus \{p_k\})$, con:
\begin{align*}
& p_k, \neg p_k \notin D \\
\iff & D \in C^{k-1}_\mathscr{L} \cap \mathscr{R}^*(S) && \text{perché non compare } p_k \\
\iff & \mathcal{v}(D) = 1 && \text{per ipotesi assurda} \\
\iff & \mathcal{v} \models D
\end{align*}.

Vi sono due casi:
\begin{enumerate}
  \item $\mathcal{v}$ soddisfa qualche letterale in $C_1 \setminus \{\neg p_k\}$. Ma allora $\mathcal{v}(C_1) = 1$ e $\mathcal{v}^+(C_1) = 1$, assurdo.
  \item $\mathcal{v}$ soddisfa qualche letterale in $C_2 \setminus \{p_k\}$, e allora $\mathcal{v}^-(C_2) = 1$, assurdo.
\end{enumerate}
Non essendoci altri casi, si è raggiunta la contraddizione che conclude la dimostrazione per assurdo, dunque $C^k_\mathscr{L} \cap \mathscr{R}^*(S)$ è
insoddisfacibile per ogni $k$, $k=0$ incluso.
\end{itemize}
Dunque $C^0_\mathscr{L} \cap \mathscr{R}^*(S)$ è insoddisfacibile, pertanto $C^0 \cap \mathscr{R}^*(S) = \{\qedsymbol\}$ e $\qedsymbol \in \mathscr{R}^*(S)$.
\end{proof}
\begin{oss}
Se $S$ è un insieme finito di clausole, la costruzione di $\mathscr{R}^*(S)$ costituisce una \textit{procedura di decisione}, cioè sia che $S$ sia insodd. sia che $S$ sia sodd. termina in tempo finito, dando la risposta corretta.
\end{oss}
\begin{proof} Infatti, essendo $S$ finito, vengono usate solo un numero finito $n = |Var(S)|$ di lettere proposizionali diverse, dunque:
\begin{itemize}
  \item letterali scrivibili su $\{p_1, \cdots, p_n\}$: $2 \cdot n$
  \item letterali diversi che occorrono: $\leq 2 \cdot n$ 
  \item clasuole scrivibili su $2 \cdot n$ letterali: $\leq 2^{2 \cdot n}$
\end{itemize} 
In $S$, quindi, occorrono al più $2^{2 \cdot n}$ clausole. \\
Si nota, ora, che la risoluzione non introduce mai nuovi letterali, dunque la sequenza $\mathscr{R}^{0}(S) \subseteq R^1(S) \subseteq \cdots \mathscr{R}^{k}(S) \subseteq \cdots$ è tale che  che ogni $\mathscr{R}^{i}(S)$ è un sottoinsieme delle $2^{2 \cdot n}$ clausole 
scrivibili su $\{p_1, \cdots, p_n\}$. \\
Dunque esiste un $t \in \omega$ tale che $\mathscr{R}^{t}(S) = \mathscr{R}^{t+1}(S)$, poiché prima o poi tutte le clausole saranno contenute; 
pertanto
$$
\mathscr{R}^{t}(S) = \mathscr{R}^{t+1}(S) = \cdots = \mathscr{R}^*(S)
$$
Se si trova $\qedsymbol \in \mathscr{R}^i(S)$, si può concludere che $S$ sia insoddisfacibile. \\
Se, al contrario, $\mathscr{R}^t(S) = \mathscr{R}^{t+1}(S)$ e $\qedsymbol \notin \mathscr{R}^t(S)$, si può concludere che $S$ sia soddisfacibile perché non ci sono due clausole con due letterali opposti.
\end{proof}
\begin{oss}
Se, invece, $S$ è un infinito di clausole, dato un qualsiasi $S_{fin} \subseteq_\omega S$ esiste $t \in \omega$ tale che $\mathscr{R}^t(S_{fin}) = \mathscr{R}^{t+1}(S_{fin}) = \mathscr{R}^*(S_{fin})$, tuttavia questo non fornisce una procedura di decisione per $S$, ma esclusivamente di \textit{semidicesione}. Questo perché in genere non si sa ``scegliere'' $S_{fin}$ e il meglio che si può fare è, presa una successione infinita di sottoinsiemi infiniti
$$
S_1 \subseteq S_2 \subseteq \cdots \subseteq S_k  \subseteq \cdots \text{ t.c. } \bigcup_i S_i = S
$$
e calcolare $\mathscr{R}^*(S_i)$ per ogni $i$: se $\qedsymbol \in S_i$ allora $S$ insoddisfacibile, altrimenti si aumenta $i$ e si procede al passo successivo.
\end{oss}

La Completezza Refutazionale non è la Completezza \textit{tout-court}. 
\`E qualcosa che è più debole, e in realtà proprio per questo è una 
proprietà desiderabile dal punto di vista computazionale. 

\begin{defi}[Deduzione per Risoluzione]
Una deduzione per risoluzione di una clausola $C$ da un insieme di clausole $S$ (indicata con $S \vdash_R C$) è una sequenza finita di clausole $C_1,C_2, \cdots, C_n$ tale che: 
\begin{itemize}
\item $C_n = C$
\item $\forall C_i,\ C_i \in S \text{ oppure } C_i = \mathbb{R}(C_j, C_k, \ell, \bar{\ell})$, con $j,k < i$
\end{itemize}
\end{defi}

In particolare, una deduzione per risoluzione della clausola vuota ($S \vdash_R \qedsymbol$) è detta \textbf{refutazione} di $S$.
\begin{teon}[di Completezza Refutazionale]
\label{thm:completezza-refutazionale}
  Un insieme di clausole $S$ è insodd. sse $S \vdash_R \qedsymbol$.
\end{teon}
Al momento, la refutazione la sappiamo costruire solo tramite il metodo $\mathscr{R}^*(S)$. 

\paragraph{Esempio}
$$
S = \{\{a, b, \neg c\}, \{a, b, c\}, \{a, \neg b\}\} \stackrel{?}{\models} \{a\}
$$
Tuttavia non sappiamo risolvere questo problema direttamente, quindi si trasforma il problema in un problema di insoddisfacibilità e si crea una refutazione:
$$
S' := \{\{a, b, \neg c\}, \{a, b, c\}, \{a, \neg b\}, \{\neg a\}\} \text{ è insodd.?}
$$
Non è soddisfacibile, poiché 
\begin{prooftree}
  \AxiomC{$\{a,b,\neg c\} \in S'$}
  \AxiomC{$\{a, b, c\} \in S$}
  \LeftLabel{\scriptsize($\mathbb{R}$ con $\ell = c)$)}
  \BinaryInfC{$\{a, b\}$}
  \AxiomC{$\{a, \neg b\} \in S'$}
  \LeftLabel{\scriptsize($\mathbb{R}$ con $\ell = b)$)}
  \BinaryInfC{$\{a\}$}
  \AxiomC{$\{\neg a\} \in S'$}
  \LeftLabel{\scriptsize($\mathbb{R}$ con $\ell = a)$)}
  \BinaryInfC{$\{\qedsymbol\}$}
\end{prooftree}
\noindent
Si noti che, se non si considera l'ultima risoluzione, si è riusciti a dedurre $a$ da dalla teoria iniziale, come richiesto ($S \vdash_R \{a\}$)!

Tuttavia non si riesce a farlo in maniera generale, infatti:
\begin{align*}
& \Gamma \models F \\
\iff & \Gamma, \neg F \text{ insodd.} & \text{per Lemma~\ref{lem:conseguenza-teoria-insodd-formula}} \\
\iff & \Gamma^c, (\neg F)^c \vdash_R \qedsymbol & \text{per Teorema}~\ref{thm:completezza-refutazionale} \\
\Longleftarrow\ & \Gamma^c \vdash_R F^c & \text{non è un } \iff \text{!!}
\end{align*}
E proprio questa è la debolezza della Completezza Refutazionale rispetto alla Completezza \textit{tout court} di un calcolo $C$ (per cui invece varrebbe $\Gamma \models F \iff \Gamma \vdash_C F$). \\
Si può dedurre un calcolo refutazionale da una deduzione per risoluzione, ma non il contrario!

Si consideri, per esempio questa semplice refutazione:
$$
\{\{b\}, \{\neg b\}, \{\neg a\}\} \vdash_R \qedsymbol
$$
ma visto che la Risoluzione non introduce mai nuovi letterali, non si potrà mai a provare 
$$
\{\{b\},\{\neg b\}\} \vdash_R \{a\}
$$
\subsection{Sistemi Assiomatici (Calcoli alla Hilbert)}
I Sistemi Assiomatici sono un tipo di calcolo tradizionale completo \textit{tout court}. Hanno una formalizzazione tra le più semplici, ma non sono in particolar modo adatti alla ricerca \textit{human-oriented} e nemmeno alla ricerca di prove tramite algoritmi. 

\begin{defi}[Calcoli alla Hilbert]
        Dato un insieme di assiomi (che sono tautologie della Logica), come per esempio 
il seguente, che è corretto e completo per la Logica Proposizionale classica
$$
\begin{cases}
        A \rightarrow (B \rightarrow A) \\
        (A \rightarrow (B \rightarrow C)) \rightarrow ((A \rightarrow B) \rightarrow (A \rightarrow C)) \\
        ( \neg B \rightarrow \neg A) \rightarrow (A \rightarrow B) 
\end{cases}
$$
con $A, B, C \in \mathscr{F}_\mathscr{L}$ e avendo regole di inferenza come il \textit{modus ponens} 

\begin{prooftree}
        \AxiomC{$A$}
        \AxiomC{$A\rightarrow B$}
        \BinaryInfC{$B$}
\end{prooftree}

una prova di $A$ da una teoria $\Gamma$ nel Calcolo alla Hilbert ($\Gamma \vdash_H A$) è una successione finita di formule:
$$
A_1, A_2, \cdots, A_u
$$
tale che: 
\begin{enumerate}
  \item $A_u = A$ 
  \item ogni $A_i$ per $i = 1, \cdots, u$ è tale che: 
    \begin{enumerate}
      \item $A_i \in \Gamma$
      \item $A_i$ è un'istanza di assioma 
      \item esistono $j,k < i$ tali che $A_j= A_k \rightarrow A_i$, quindi 
        \begin{prooftree}
          \AxiomC{$A_k$}
          \AxiomC{$A_k \rightarrow A_i$}
          \BinaryInfC{$A_i$}
        \end{prooftree}
    \end{enumerate}
\end{enumerate}
\end{defi}

\begin{teo}[Completezza Forte del Calcolo H]
$\Gamma \models A \iff \Gamma \vdash_H A$, anche per teorie $\Gamma$ infinite. 
\end{teo}

Il Calcolo H non è particolarmente adatto alla deduzione automatica, come 
sottolineato precedentemente. I vari tipi di calcolo corrispondono ad esigenze 
diverse: quando la necessità è la deduzione automatica, vi sono ottime 
ragioni per preferire il Calcolo Refutazionale. Diamo ora qualche evidenza 
del perché non sia così saggio utilizzare il Calcolo H. Quest'ultimo è 
semplice dal punto di vista concettuale, ma tirar fuori prove è più complicato. 

\subsubsection{Differenze tra i due Calcoli}
Differenze nel verificare se  $\forall A \in \mathscr{F}_\mathscr{L},\ \neg \neg A \models A$ è vera. 

\paragraph{Calcolo R}
Bisogna inizialmente trasformare il $\forall A \in \mathscr{F}_\mathscr{L}$ in lettere proposizionali $\in \mathscr{L}$:
$$
\neg \neg p \models p 
$$
Si studia l'insoddisfacibilità di 
$$
\{ \neg \neg p, \neg p\} \models \bot
$$
che si traduce in forma normale e si cerca di refutarlo: 
$$
\{\{p\}, \{\neg p \}\} \vdash_R \qedsymbol
$$
Si risolve con risoluzioni \textit{automatiche}: $\mathbb{R}(\{p\}, \{\neg p\}; p, \neg p) =  \qedsymbol$, pertanto la conseguenza logica è vera.

\paragraph{Calcolo H}
Nel Calcolo di Hilbert si può tranquillamente ragionare sulle metavariabili, tuttavia bisogna ``inventarsi'' una dimostrazione (MP = Modus Ponens):
\begin{prooftree}
  \AxiomC{}
  \LeftLabel{\scriptsize(1)}
  \UnaryInfC{$\neg \neg A \rightarrow (\neg \neg \neg \neg A \rightarrow \neg \neg A)$}
  \AxiomC{}
  \RightLabel{\scriptsize{$\in \Gamma$}}
  \UnaryInfC{$\neg \neg A$}
  \LeftLabel{\scriptsize{MP}}
  \BinaryInfC{$\neg \neg \neg \neg A \rightarrow \neg \neg A$}
  \AxiomC{}
  \RightLabel{\scriptsize(3)}
  \UnaryInfC{$(\neg \neg \neg \neg A \rightarrow \neg \neg A) \rightarrow (\neg A \rightarrow \neg \neg \neg A)$}
  \RightLabel{\scriptsize{MP}}
  \BinaryInfC{$\neg A \rightarrow \neg \neg \neg A$}
\end{prooftree}
\begin{prooftree}
  \AxiomC{$\neg A \rightarrow \neg \neg \neg A$}
  \AxiomC{}
  \RightLabel{\scriptsize(3)}
  \UnaryInfC{$(\neg A \rightarrow \neg \neg \neg A) \rightarrow ( \neg \neg A \rightarrow A)$}
  \RightLabel{\scriptsize{MP}}
  \BinaryInfC{$\neg \neg A \rightarrow A$}
  \AxiomC{}
  \RightLabel{\scriptsize{$\in \Gamma$}}
  \UnaryInfC{$\neg \neg A$}
  \RightLabel{\scriptsize{MP}}
  \BinaryInfC{$A$}
\end{prooftree}
Il calcolo H non presenta un calcolo meccanico e facilmente automatizzabile. Non è facile scegliere quale assioma applicare.

\paragraph{Esercizio}
Dimostrare che $\models A \rightarrow A$

Si prenda una formula $B$ soddisfacibile, già provata, ossia $\models_H B$. 
\begin{prooftree}
  \AxiomC{$B$}
  \AxiomC{$B \rightarrow ( A \rightarrow B)$}
  \BinaryInfC{$A \rightarrow B$}
  \AxiomC{$A \rightarrow (B \rightarrow A)$}
  \AxiomC{$(A \rightarrow (B \rightarrow A)) \rightarrow (A \rightarrow A)$}
  \BinaryInfC{$(A \rightarrow B) \rightarrow (A \rightarrow A)$}
  \BinaryInfC{$A \rightarrow A$}
\end{prooftree}

\subsection{Procedura refutazionale di Davis-Putnam}
Si supponga che sia stato definito un insieme di clausole
$$
S = \{\{p,q\}, \{p, \neg q\}, \{\neg p, q\}, \{\neg p, \neg q\}\} 
$$
e ci si chiede se sia refutabile.
Un umano può vedere a primo d'occhio che la soluzione più facile è:
\begin{prooftree}
  \AxiomC{$p,q$}
  \AxiomC{$p,\neg q$}
  \BinaryInfC{$p$}
  \AxiomC{$\neg p,q$}
  \AxiomC{$\neg p,\neg q$}
  \BinaryInfC{$\neg p$}
  \BinaryInfC{$\{\qedsymbol\}$}
\end{prooftree}

Utilizzando, invece, il calcolo refutazionale $\mathscr{R}^*(S)$ estensivamente necessiterebbero 35 passaggi visto che bisogna provare tutti i risolventi possibili (e.g., anche su $C_1 = \{p,q\}$ e $C_2 = \{\neg p, q\}$, e così via).

Vorremmo designare una tecnica che permetta di mantenere la completezza refutazionale selezionando, in qualche modo, i risolventi da calcolare. 

\begin{defi}[Sussunzione]
Una clausola $C_1$ \textbf{sussume} $C_2$ sse $C_1 \subset C_2$, ossia è un insieme proprio di $C_2$. \\
In termini logici: $\models C_1 \rightarrow C_2$, e quindi  $\{C_1, C_2\} \equiv \{C_1\}$.
\end{defi}

\begin{defi}[Regola di Sussunzione]
Sia $S$ un insieme di clausole e sia $S'$ ottenuto da $S$ eliminando tutte le clausole sussunte. Allora si può concludere che $S \equiv S'$. 
\end{defi}

\begin{oss}
$S'$ non contiene sussunte, ossia non è ulteriormente riducibile per sussunzione.
\end{oss}

\begin{defi}[Clausola Banale]
Una clausola $C$ è detta \textbf{banale} (trivial) se contiene sia $\ell$ che il sua opposto $\bar{\ell}$ per qualche letterale $\ell$. Ne segue che $C \equiv \top$ o $\models C$. 
\end{defi}

\begin{defi}[Regola di rimozione banali]
Se $S'$ è ottenuta rimuovendo da $S$ tutte le banali, $S \equiv S'$.
\end{defi}

\begin{oss}
Sia $D = \mathbb{R}(C_1, C_2; \ell, \bar{\ell})$ la risoluzione di clausole $C_1$ e $C_2$ non banali, allora $\ell \notin D$ e $\bar{\ell} \notin D$, cioè $(C_1 \setminus \{\ell\}) \cup (C_2 \setminus \{ \bar{\ell}\}) = (C_1 \cup C_2) \setminus \{\ell, \bar{\ell}\}$
\end{oss}

\begin{defi}[Passo semplice di DPP]
Dato un  input $S$ finito, già ripulito di banali e sussunte, un passo di \textit{Davis-Putnam Procedure} si articola nei seguenti ``micropassi'': 
\begin{enumerate}
  \item Scegliere una lettera proposizionale $p \in Var(S)$. $p$ sarà detto il \textit{pivot} del passo.
  \item $S'$ è l'insieme delle $p$-esonerate, ossia l'insieme delle clausole in $S$ in cui non occorre $p$ come lettera proposizionale (né come $p$, né come $\neg p$).
  \item $S''$ è l'insieme delle $p$-risolventi ed è l'insieme delle clausole ottenute per risoluzione sul pivot $p$ in $S\setminus S'$. 
  \item $S'''$ è l'insieme  $S' \cup S''$ ripulito. È l'output del passo di DPP.
\end{enumerate}
\end{defi}

\subsubsection{Esempi di DPP}
\paragraph{1}
Sia $S_0 = \{\{a,b,\neg c\}, \{a, \neg b, d\}, \{a, \neg b, \neg c, \neg d\}, 
\{\neg a, d\}, \{\neg a, \neg c, \neg d\}, \{c\}\}$. 
\begin{itemize}
  \item $S_0$ è ripulito.
    \begin{itemize}
      \item pivot: $c$
      \item $c$-esonerate: $\{a, \neg b, d\}$ e $\{\neg a, d\}$
      \item $c$-risolventi: $\{a,b\}, \{a, \neg b, \neg d\}, \{\neg a, \neg d\}$
      \item output ripulito: $\{\{a, \neg b, d\}, \{\neg a, d\}, \{a, b\}, \{a, \neg b, \neg d\}, \{\neg a, \neg d\}\}$
    \end{itemize}
  \item
    \begin{itemize}
      \item pivot: $a$
      \item $a$-esonerate: $\emptyset$
      \item $a$-risolventi: $\{\neg b, d\}, \{\neg b, d, \neg d\}, \{b, d\}, \{\neg b, d, \neg d\}, \{b, \neg d\}, \{\neg b, \neg d\}$
      \item output ripulito: $\{\{\neg b, d\}, \{b, d\}, \{b, \neg d\}, \{\neg b, \neg d\}\}$
    \end{itemize}
  \item
    \begin{itemize}
      \item pivot: $b$
      \item $b$-esonerate: $\emptyset$
      \item $b$-risolventi: $\{d\},\{d, \neg d\}, \{\neg d, d\} \{\neg d\}$
      \item output ripulito: $\{\{d\}, \{\neg d\}\}$
    \end{itemize}
  \item 
    \begin{itemize}
      \item pivot: $d$
      \item $d$-esonerate: $\emptyset$
      \item $d$-risolventi: $\qedsymbol$
      \item output ripulito: $\{\qedsymbol\}$
    \end{itemize}
\end{itemize}
Dato che è stata ottenuta la clausola vuota, si dichiara la clausola iniziale $S_0$ insoddisfacibile. 
\paragraph{2}
Sia $S_0 = \{\{a, \neg b, c\}, \{b, \neg c\}, \{a,c,\neg d\}, \{\neg b, \neg d\}, \{a,b,d\}, \{\neg a,b,d\}, \{b, \neg c, d\}, \{c, \neg c\}\}$. 
\begin{itemize}
  \item $S_0$ ripulito: $\{\{a, \neg b, c\}, \{b, \neg c\}, \{a,c,\neg d\}, \{\neg b, \neg d\}, \{a,b,d\}, \{\neg a,b,d\}\}$
    \begin{itemize}
      \item pivot: $b$
      \item $b$-esonerate: $\{a, c, \neg d\}$
      \item $b$-risolventi: $\{a, c, \neg c\}, \{a,c,d\}, \{a, \neg a, c, d\}, \{\neg c, \neg d\}, \{a, \neg d, d\}, \{\neg a, \neg d, d\}$
      \item output ripulito: $S_1 := \{\{a, c, \neg d\}\}, \{a, c,d\}, \{\neg c, \neg d\}$
    \end{itemize}
  \item
    \begin{itemize}
      \item pivot: $c$
      \item $c$-esonerate: $\emptyset$
      \item $c$-risolventi: $\{a, d, \neg d\}, \{a, \neg d\}$
      \item output ripulito: $S_2 := \{\{a, \neg d\}\}$
    \end{itemize}
  \item 
    \begin{itemize}
      \item pivot: $a$
      \item $a$-esonerate: $\emptyset$
      \item $a$-risolventi: $\emptyset$
      \item output ripulito: $S_3 := \emptyset$
    \end{itemize}
\end{itemize}
Mostreremo che questo vuol dire che $S_0$ è soddisfacibile. \\
La lettera proposizionale $d$ non è mai stata scelta come lettera pivot, quindi è una \textit{fuoriuscita}.  

Delineamo, prima di affrontare la dimostrazione, la strategia che permette di costruire un assegnamento che soddisfa $S_0$ dopo un'esecuzione di DPP giunta a buon fine. \\
Sia $\mathcal{v}: \mathscr{L} \rightarrow \{0,1\}$ tale che $\mathcal{v} \models S_0$ definita come:
$$
\mathcal{v} := 
\begin{cases}
        d :& \mathcal{v}(d) = 0 ~~~ \text{alle fuoriuscite basta un valore fissato arbitrariamente} \\ 
        a :& \mathcal{v}(a) = 1 ~~~ \text{soddisfa } S_2 \\
        c :& \mathcal{v}(c) = 0 ~~~ \text{soddisfa } S_1 \\
        b :& \mathcal{v}(b) = 1 ~~~ \text{soddisfa } S_0 \\
\end{cases}
$$
Con $\mathcal{v}(c)$ si era liberi perché tutte le clausole erano già soddisfatte dai precedenti assegnamenti.

\subsubsection{Teorema di completezza (e correttezza) refutazionale di DPP}
\begin{teon}
\label{thm:completezza-refutazionale-dpp}
Un insieme \textbf{finito} $S$ di clausole tale che $|Var(S)| = n$ è insoddisfacibile sse entro al più $n$ passi si ottiene la clausola vuota $\qedsymbol$. \\
$S$ è soddisfacibile sse entro al più $n$ passi si ottiene l'insieme vuoto di clausole $\emptyset$. \\
Non vi sono altri modi di terminare. 
\end{teon}

\begin{proof}[Dimostrazione di Terminazione]
Sia $DPP(S) := S_0, S_1, \cdots, S_k$ una sequenza di clausole, dove $S_i$ è ottenuto da $S_{i-1}$ attraverso un passo di DPP sul pivot $q_i \in Var(S)$. \\
Si osserva che $S_i$ non conterrà più alcuna occorrenza di $q_i$ e, quindi, dopo al più $k \leq n$ passi si ottiene $Var(S_k) = \emptyset$, dunque o $S_k = \{ \qedsymbol \}$ oppure $S_k = \emptyset$. 
\end{proof}

\begin{proof}[Dimostrazione di  Correttezza e Completezza Refutazionale di DPP]
$$
\text{Correttezza di DPP:}
\begin{cases}
  S_k = \{\qedsymbol\} \implies S_0 \text{ insoddisfacibile } \\
  S_0 \text{ soddisfacibile } \implies S_k = \emptyset & \text{(contronominale)}
\end{cases}
$$
Dimostrata dal Lemma~\ref{lem:correttezza-risoluzione} di Correttezza della Risoluzione {[visto che $S_k \equiv S_0$ (?!)]}.
$$
\text{Completezza di DPP:}
\begin{cases}
  S_0 \text{ insoddisfacibile } \implies S_k = \{\qedsymbol\} \\
  S_k = \emptyset \implies S_0 \text{ soddisfacibile } & \text{(contronominale)}
\end{cases}
$$
Dimostriamo la contronominale, chiamata anche \textit{Lemma di Model Building} poiché la dimostrazione si occupa di mostrare come costruire l'assegnamento che soddisfa $S$. 

Per induzione decrescente su $k$:
\begin{itemize}
  \item \textbf{base} ($j = k$): $S_k = \emptyset$ è soddisfacibile da qualsiasi assegnamento.
  \item \textbf{passo induttivo} ($j$): Dato per ipotesi induttiva $\mathcal{v} : \mathscr{L} \rightarrow \{0,1\}$ tale che $\mathcal{v} \models S_{i+1}$, si definiscono le due varianti 
  \begin{align*}
    \mathcal{v}^+ : \mathscr{L} \rightarrow \{0,1\} ~~~ \mathcal{v}^+(p) = 1 \\
    \mathcal{v}^- : \mathscr{L} \rightarrow \{0,1\} ~~~ \mathcal{v}^-(p) = 0
  \end{align*}
  dove $p$ è il pivot di $S_i \leadsto S_{i+1}$, mentre $\mathcal{v}(q) = \mathcal{v}^+(q) = \mathcal{v}^-(q)$ per tutte le lettere proposizionali $q \neq p$.
  
  Si mostrerà che una delle due varianti soddisfa $S_i$. \\
  Per assurdo, si assume $\mathcal{v}^+ \nvDash S_i$ e $\mathcal{v}^- \nvDash S_i$. \\
  Allora esistono $C_1, C_2 \in S_i$ tali che $\mathcal{v}^+(C_1) = 0$ e $\mathcal{v}^-(C_2) = 0$.
  \begin{itemize}
    \item $p \notin C_1 e \neg p_1 \notin C_1$: allora $C_1$ sarebbe $p$-esonerata, dunque $C_1 \in S_{i+1}$. Per ipotesi induttiva $\mathcal{v} \models S_{i+1}$, quindi anche $\mathcal{v} \models C_1$. \\
    $\Rightarrow \mathcal{v}^+ \models C_1$, assurdo.
    \item $\neg p \in C_1$: altrimenti, se $p \in C_1$, $\mathcal{v}^+(C_1) = 1$. Assurdo
  \end{itemize}
  Analogamente per $p \in C_2$. \\
  Ne segue che $D = \mathbb{R}(C_1, C_2; \neg p, p)$ e che $D \in p$-risolventi. Quindi $D \in S_{i+1}$, il che vuol dire che $\mathcal{v} \models D$. Tuttavia:
  \begin{align*}
    \mathcal{v} & \models D \\
    \implies \mathcal{v}^+ & \models D \text{ oppure } \mathcal{v}^- \models D & \mathcal{v}^\pm \text{ aggiunge una lettera proposizionale a } \mathcal{v} \\
    \implies \mathcal{v}^+ & \models C_1 \text{ oppure } \mathcal{v}^- \models C_2 & \text{per def. }\mathcal{v}^\pm \\
    \implies \mathcal{v}^+ & \models S_i \text{ oppure } \mathcal{v}^- \models S_i \\
    \implies \bot && \text{per ipotesi assurda}
  \end{align*}
  Dunque $S_i$ è soddisfacibile e, pertanto, anche  $S_0$.
\end{itemize}
\end{proof}

\begin{oss}
Sia $S$ un insieme finito di clausole tale che $Var(S) = \{p_1, \cdots, p_n\}$. 
Allora $DPP(S)$ termina in $k \leq n$ passi. Se $k \leq n \leq ||S||$, si potrebbe concludere che si ha una procedura che funziona in tempo 
polinomiale e decide se $S$ è soddisfacibile o meno, e quindi $P = NP$. 
\end{oss}

Se si potesse garantire che $||S_i||$ sia sempre polinomiale rispetto a $||S||$ allora davvero $k \leq n$ passi di DPP porterebbero a un tempo di esecuzione complessivo che è polinomiale rispetto a $||S||$. \\
E dunque $SAT \in P$, e $P = NP$. Purtroppo questo non si può garantire.

Un risultato, dovuto ad Haken, afferma che ogni prova per refutazione del 
\textit{Principio della Piccionaia} su $n$ ``piccioni''
richiede tempo almeno $T(n) = \Omega(2^n)$. 


\begin{defi}[Principio della Piccionaia]
        Il Principio della Piccionaia, notazionalmente espresso su un 
        numero naturale $n$ come 
        $$
        PHP(n)
        $$
        afferma che $n+1$ piccioni non possono occupare 
        $n$ posti nella piccionaia in modo che ogni posto abbia al più un 
        piccione. 
\end{defi}

Come formalizzare in clausole il $PHP(n)$? Definendo $P$ i ``piccioni'' e 
$H$ i ``posti'', si può definire
$$
\bigwedge_{i \in P} \bigvee_{j \in H} p_{ij} ~~~ \text{ (ogni piccione ha trovato posto)}
$$

Questo, però va unito al fatto che ogni piccione ha al più un posto: 
$$
\bigwedge_{i \neq j ~ i,j \in P}\bigwedge_{k \in H} (\neg p_{ik} \lor \neg p_{jk}) ~~~ \text{ nessuna coppia di piccioni sta nel posto }k 
$$
Quindi, la formalizzazione finale sarà 
$$
PHP(n) := \bigwedge_{i \in P} \bigvee_{j \in H} p_{ij} ~~ \land ~~ \bigwedge_{i \neq j ~ i,j \in P}\bigwedge_{k \in H} (\neg p_{ik} \lor \neg p_{jk})
$$
Mostrare che il Principio della Piccionaia è vero consiste nel mostrare che 
$PHP(n)$ è insoddisfacibile, ossia che $PHP(n) \in CNFUNSAT\ \forall n \in \mathbb{N}$. 
Haken ha dimostrato che la risoluzione mediante refutazione di questo problema impiega, per ogni $n$, tempo esponenziale.  

\subsubsection{Complessità di DPP}
Dato che i passi di DPP sono ``pochi''—$k \leq |Var(S)|$—anche se nel caso 
peggiore DPP richiede tempo esponenziale, nella pratica è comunque un 
algoritmo molto più efficiente di $\mathscr{R}^*$ e delle tavole di verità. \\
Alcuni frammenti, ossia sottolinguaggi di CNFSAT, sono noti avere tempo di decisione con DPP che è polinomiale, come KROMSAT e HORNSAT. \\
Una CNF è HORN sse ha solo clausole di Horn, ossia della forma:
\begin{align*}
  \qedsymbol &&
  \stackrel{\text{(unità)}}{\{p\}} &&
  \stackrel{\text{(solo negati)}}{\{\neg p_1, \neg p_2, \cdots\}} &&
  \stackrel{\text{(un solo positivo)}}{\{\neg p_1, \neg p_2, \cdots, q\}}
\end{align*}
Una CNF è KROM sse ha solo clausole di Krom, ossia se ha al più due letterali ($KROMSAT = 2CNFSAT$). 

\subsubsection{Davis Putnam Logemann Loveland Procedure}
\label{dpll}
La DPLL è un metodo di ``reingegnerizzazione'' della DPP. Su un insieme finito $S$ di clausole, DPLL cerca di costruire un assegnamento che soddisfi $S$.
\begin{enumerate}
  \item L'idea è di costruire un assegnamento parziale che viene esteso ad ogni passo di una nuova lettera proposizionale $p$, chiamata pivot.
  \item Se si riesce ad assegnare tutte le lettere in $Var(S)$ si è ottenuto un assegnamento che mostra $S$ soddisfacibile. \\
  Se non si giunge a tal punto, il teorema di completezza e correttezza di DPLL (che non vediamo) dimostra che $S$ è insoddisfacibile.
  \item Ad ogni passo si propaga tutta l'informazione  che si guadagna estendendo l'assegnamento al pivot. \\
  Sostanzialmente, quello che era il passo finale della DPP si utilizza come azione fondamentale nella DPLL.
  \item Se non ci sono informazioni sfruttabili per la scelta del pivot—guidata da regole che vedremo—allora si ``spezza'' la procedura in due parti: una in cui si assegna al pivot il valore $1$ e una a cui si assegna al pivot il valore $0$. \\
  \item La prova risulta dunque in una struttura ad \textit{albero} i cui rami si visitano in ``backtracking''. L'implementazione del backtracking è soggetto di ampie ricerche (e.g., backtracking non cronologico)
  \item Se in un ramo si raggiunge $\emptyset$ si è costruito un assegnamento che soddisfa l'insieme iniziale e se su \textit{tutti} i rami si raggiunge $\qedsymbol$, allora $S$ è insoddisfacibile.
\end{enumerate}

Le regole utilizzate dalla DPPL sono quelle della DPP adattate a questo contesto. \\
Il punto di partenza è un \textit{assegnamento vuoto}.

\begin{defi}[Assegnamento Parziale e Vuoto]
Un assegnamento parziale è una funzione parziale $\mathcal{v}: \mathscr{L} \rightarrow \{0,1,?\}$. \\
Un \textit{assegnamento vuoto} è un assegnamento parziale tale che $\mathcal{v}(p_i) = ?\ \forall p_i \in \{p_1, \cdots, p_n\}$. \\
Un \textit{assegnamento completo} o totale sulle prime $n$ lettere proposizionali è una mappa $\mathcal{v}: \{p_1, \cdots, p_n\} \rightarrow \{0,1,?\}$ tale che $\mathcal{v}(p_i) \neq ?\ \forall p_i \in \{p_1, \cdots, p_n\}$.
\end{defi}

\paragraph{Regole di DPLL}
\begin{itemize}
  \item \textit{Regola iniziale}: $\emptyset \vdash S$ è la radice dell'albero di prova. 
  \item \textit{Sussunzione}: se $\mathcal{v}(p_i) = 1$ allora si possono cancellare a $S$ tutte le clausole che contengono  il letterale $p_i$
    \begin{prooftree}
      \def\fCenter{\mbox{\ $\vdash$\ }}
      \AxiomC{$\mathcal{v}, \mathcal{v}(p_i) = 1 \fCenter S \cup \{\{p_i\} \cup C\}$}
        \UnaryInfC{$\mathcal{v}, \mathcal{v}(p_i) = 1 \fCenter S$}
    \end{prooftree}
  analogamente, se $\mathcal{v}(p_i) = 0$, allora si possono cancellare da $S$ tutte le clausole che contengono il letterale $\neg p_i$.
  \item \textit{Risoluzione unitaria}: si fanno Risolventi in cui una delle due clausole ha un solo letterale. Viene quindi codificata come assegnamento, e alla clausola rimanente è inutile avere il letterale opposto. \\
  Se $\mathcal{v}(p_i) = 0$ si cancella da ogni clausola di $S$ il letterale $p_i$
    \begin{prooftree}
      \AxiomC{$\{\neg p_i\}$}
      \AxiomC{$\{p_i\} \cup C$}
      \RightLabel{\scriptsize$\mathbb{R}$}
        \BinaryInfC{$C$}
    \end{prooftree}
  Ossia, in termini di ``nodi'' DPLL
    \begin{prooftree}
      \AxiomC{$\mathcal{v}, \mathcal{v}(p_i) = 0 \vdash S \cup \{\{p_i\}\cup C\}$}
        \UnaryInfC{$\mathcal{v},\mathcal{v}(p_i) = 0 \vdash S \cup \{C\}$}
    \end{prooftree}
  mentre se $\mathcal{v}(p_i) = 1$, allora si elimina da ogni clausola di $S$ il letterale $\neg p_i$.  
  \item \textit{Asserzione}: se $S$ contiene la clausola $\{p_i\}$, allora si estende $\mathcal{v}$ ponendo $\mathcal{v}(p_i) = 1$, cancellando $\{p_i\}$ da $S$
    \begin{prooftree}
      \AxiomC{$\mathcal{v}\vdash S \cup \{\{p_i\}\}$}
        \UnaryInfC{$\mathcal{v}, \mathcal{v}(p_i) = 1 \vdash S$}
    \end{prooftree}
  mentre si fa l'opposto se $S$ contiene $\{\neg p_i\}$.
  \item \textit{Letterale puro}: Se il letterale $p_i$ occorre in $S$ e $\neg p_i$ non occorre, allora si estende $\mathcal{v}$ ponendo $\mathcal{v}(p_i) = 1$,
    \begin{prooftree}
      \AxiomC{$\mathcal{v}\models S$}
      \RightLabel{\scriptsize{se $p_i \in C \in S, \neg p_i \notin C\ \forall C \in S$}}
         \UnaryInfC{$\mathcal{v}, \mathcal{v}(p_i)=1 \vdash S$}
    \end{prooftree}
    mentre si fa l'opposto se $\neg p_i$ occorre in $S$ e $p_i$ non occorre in $S$, ponendo $\mathcal{v}(p_i) = 0$.
  \item \textit{Spezzamento}: in ogni momento, si può biforcare la prova in due sottoprove, dando origine ad una struttura ad albero, in cui in una si pone per il pivot scelto $\mathcal{v}(p) = 1$ e nell'altra si pone $\mathcal{v}(p)= 0$. 
    \begin{prooftree}
      \AxiomC{$\mathcal{v} \vdash S$} 
        \UnaryInfC{$\mathcal{v}, \mathcal{v}(p_i) = 0 \vdash S ~~~~ ||  ~~~~ \mathcal{v}, \mathcal{v}(p_i) = 1 \vdash S$}
    \end{prooftree}
  \item \textit{Terminazione}: se in un ramo si ottiene $\mathcal{v} \vdash \emptyset$ allora si prova che $\mathcal{v}$ è completo su $Var(S)$ e $\mathcal{v} \models S$. Al contrario, se su tutti i rami si ottiene $\mathcal{v} \vdash \qedsymbol$, allora $S$ è insoddisfacibile.
    \item Ogni ramo ha come foglia $\mathcal{v} \vdash \emptyset$ oppure $\mathcal{v} \vdash \qedsymbol$.
\end{itemize}
