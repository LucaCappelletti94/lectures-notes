\providecommand{\main}{../..}
\documentclass[\main/main.tex]{subfiles}
\begin{document}
\chapter{Alcune definizioni base}
\section{La convessità}
\begin{definition}[Insieme convesso]
    Un insieme \(X \subset \R^n\) è convesso se comunque presi due punti \(\bmx,\bmy \in X\), allora \(\lambda\bmx + (1-\lambda)\bmy \in X\), per ogni \(\lambda \in \sqr{0,1}\), cioè tutti i punti della \textbf{combinazione convessa} appartengono all'insieme convesso da cui sono presi i due punti.

    La proprietà di convessità è invariante rispetto alle operazioni di moltiplicazione con uno scalare, unione e intersezione con un altro insieme convesso.
\end{definition}
\begin{definition}[Funzione convessa]
    Una funzione \(f: \R^n \rightarrow \R \) è convessa se il suo dominio è un insieme convesso \(X \subseteq \R^n\) e comunque presi due punti \(\bmx, \bmy \in X\), il valore della funzione nella combinazione convessa risulta minore o uguale alla combinazione convessa dei valori della funzione nei due punti:
    \[
        f(\lambda\bmx + (1-\lambda)\bmy) \leq \lambda f\rnd{\bmx} + (1-\lambda)f(\bmy) \qquad \forall \lambda \in \sqr{0,1}
    \]
    La proprietà di convessità è invariante rispetto a moltiplicazione con uno scalare e somma tra funzioni convesse.

    Vale inoltre che la funzione \(\max \) di una o più funzioni convesse e che il luogo dei punti \(\bmx \) per i quali vale che \(f\rnd{\bmx} \leq \alpha \) è convesso.
\end{definition}
\begin{definition}[Problema convesso]
    Un problema di ottimizzazione con funzione obiettivo e regione ammissibile entrambe convesse viene detto problema convesso.
\end{definition}
\section{Massimi e minimi locali}
\begin{definition}[Minimo globale]
    Un punto \(\bmxo \in X\) è un punto di minimo globale di \(f\rnd{\bmx}\) se:
    \[
        f\rnd{\bmxo} \leq f\rnd{\bmx} \quad \forall \bmx \in X
    \]\end{definition}
\begin{definition}[Minimo locale]
    Un punto \(\bmxo \in X\) è un punto di minimo locale di \(f\rnd{\bmx}\) se esiste un intorno aperto \(I(\bmxo, \epsilon)\) di \(\bmxo \) avente raggio \(\epsilon >0\) tale che:
    \[
        f\rnd{\bmxo} \leq f\rnd{\bmx} \quad \forall \bmx \in X \cap I(\bmxo, \epsilon)
    \]\end{definition}

\chapter{Ottimizzazione non vincolata}
\begin{definition}[Direzione di discesa]
    Data una funzione \(f:\R^n \rightarrow \R \), un vettore \(\bmd \in \R^n\) si dice \textbf{direzione di discesa} per \(f\) in \(\bmx \) se il valore della funzione del punto ottenuto seguendo la direzione per uno step \(\lambda \) risulta minore del valore iniziale:
    \[
        \exists \lambda > 0: f(\bmx + \lambda\bmd) < f\rnd{\bmx}
    \]\end{definition}
\begin{definition}[Derivata direzionale]
    Sia data una funzione \(f: \R^n \rightarrow \R \), un vettore \(\bmd \in \R^n\) e un punto dove \(f\) è definita. Se esiste il limite:
    \[
        \lim_{\lambda\rightarrow0^+} \frac{f(\bmx + \lambda\bmd) - f\rnd{\bmx}}{\lambda}
    \]    allora tale limite prende il nome di \textbf{derivata direzionale} della funzione \(f\) nel punto \(\bmx \) lungo la direzione \(\bmd \)
\end{definition}

\section{Condizioni necessarie di ottimalità del primo ordine}
\begin{theorem}[Condizioni necessarie di ottimalità del primo ordine]
    Data una funzione \(f: \R^n \rightarrow \R \), derivabile in \(\bmxo \in \R^n\), condizione necessaria affinché il punto \(\bmxo \) sia un minimo locale per \(f\) è che il gradiente della funzione calcolato in \(\bmxo \) sia nullo.
    \[
        \nabla f\rnd{\bmxo} = 0
    \]\end{theorem}
\section{Condizioni necessarie di ottimalità del secondo ordine}
\begin{theorem}[Condizioni necessarie di ottimalità del secondo ordine]
    Data una funzione \(f: \R^n \rightarrow \R \) di classe \(\bm{C}^2\rnd{\bmxo}\), condizione necessarie affinché il punto \(\bmxo \) sia un minimo locale per \(f\) è che il gradiente della funzione calcolato in \(\bmxo \) sia nullo e che valga la relazione seguente:
    \[
        \bmd^T \matr{H} \rnd{\bmxo}\bmd \geq 0 \quad \forall \bmd \in \R^n
    \]    Cioè l'hessiana è definita come \textbf{semi-positiva}.
\end{theorem}
\section{Condizioni necessarie di ottimalità in senso stretto del secondo ordine}
\begin{theorem}[Condizioni necessarie di ottimalità del secondo ordine]
    Data una funzione \(f: \R^n \rightarrow \R \) di classe \(\bm{C}^2\rnd{\bmxo}\), condizione necessarie affinché il punto \(\bmxo \) sia un minimo locale in \textbf{senso stretto} per \(f\) è che il gradiente della funzione calcolato in \(\bmxo \) sia nullo e che valga la relazione seguente:
    \[
        \bmd^T \matr{H} \rnd{\bmxo}\bmd > 0 \quad \forall \bmd \in \R^n
    \]    Cioè la matrice hessiana \(\matr{H}\) è \textbf{definita positiva}.
\end{theorem}

\chapter{Programmazione quadratica}
Nella programmazione quadratica si approssima \(f\) con il seguente modello quadratico, dove \(\matr{Q} \) è la matrice hessiana:
\[
    \min f\rnd{\bmx} = \frac{1}{2}\bmxt \matr{Q}\bmx + \bmbt \bmx
\]Esistono pochi casi possibili:

\begin{description}
    \item[Se \(\matr{Q}\) non è semi-definita positiva] \(f\) non ha un punto di minimo.
    \item[Se \(\matr{Q}\) è definita positiva] \(\bmxo = \matr{Q}^{-1}\bmb \) è l'unico minimo globale.
    \item[Se \(\matr{Q}\) è definita semi-positiva]
          \begin{description}
              \item[Se \(\matr{Q}\) non è singolare]  \(\bmxo = \matr{Q}^{-1}\bmb \) è l'unico minimo globale.
              \item[Se \(\matr{Q}\) è singolare] non esiste una soluzione o esistono infinite soluzioni.
          \end{description}
\end{description}

\chapter{Convergenza}
Ovviamente un algoritmo è buono se converge rapidamente.

\section{Algoritmo convergente localmente e globalmente}
\subsection{Convergente localmente}
Un algoritmo è \textbf{convergente localmente} quando converge solo se il punto \(\bmx_0\) da cui parte è in un intorno del punto ottimo \(\bmxo \).
\subsection{Convergente globalmente}
Un algoritmo è \textbf{convergente globalmente} quando converge partendo da qualsiasi punto \(\bmx \) del dominio.

\section{Velocità di convergenza}
\subsection{Q-lineare}
Quando il rapporto tra lo step \(k\) e lo step \(k+1\) mantiene un valore costante.

\subsection{Q-super-lineare}
Quando il rapporto tra lo step \(k\) e lo step \(k+1\) all'infinito è nullo.

\subsection{Q-quadratica}
Quando il rapporto tra lo step \(k\) quadro e lo step \(k+1\) mantiene un valore costante.

\chapter{Metodi di ottimizzazione continua}
Si tratta del problema di determinare a partire dallo step \(k\) lo step \(k+1\) in modo tale da avvicinarsi all'ottimo della funzione.

Esistono due strategie:

\begin{description}
    \item[Line search] Si determina una direzione e quindi si stabilisce una distanza con cui muoversi in questa direzione.
    \item[Trust region] Si determina un raggio (una distanza) di confidenza e quindi si stabilisce una direzione nel limite di questa circonferenza verso cui muoversi.
\end{description}

Esiste chiaramente un trade-off tra velocità e precisione nello stabilire la distanza con cui muoversi.

\section{Condizioni di Wolfe}
Per essere efficace, la line-search approssimata richiede che siano rispettate le condizioni di Wolfe. Esse sono due, una di \textbf{decremento sufficiente} ed una di \textbf{curvatura}, dove i coefficienti \(\bmc \) sono tali che \(0<c_1<c_2<1\)

\begin{figure}
    \begin{subfigure}{0.49\textwidth}
        \begin{align*}
            f\rnd{\bmx+\a \bmd} & \leq f\rnd{\bmx} + c_1 \a \nabla {f\rnd{\bmx}}^T \bmd
        \end{align*}
        \caption{Condizione di decremento sufficiente}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \begin{align*}
            {\nabla f\rnd{\bmx+\a \bmd}}^T \bmd & \geq c_2 \nabla {f\rnd{\bmx}}^T \bmd
        \end{align*}
        \caption{Condizione di curvatura}
    \end{subfigure}
    \caption{Condizioni di Wolfe}
\end{figure}

Le condizioni di Wolfe forti introducono un vincolo di segno sulla curvatura (valore assoluto).

\section{Metodo di Armijo per stabilire la stepsize}
Si itera riducendo gradualmente la distanza di un fattore \(\sigma \), usualmente pari circa a \(0.9\) sino a che il valore dello step successivo è più vicino all'ottimo dello step corrente. Nei metodi Newton e quasi Newton il coefficiente della distanza è inizializzato usualmente a 1.

\section{Convergenza di metodi LS approssimati}
Se definiamo \(\theta_k \) come l'angolo tra \(\bmd_k \) e \(-\nabla f_k \), allora possiamo determinare il coseno dell'angolo come:
\[
    \cos \theta_k = \frac{
        -\nabla {f\rnd{\bmx}}_k^T \bmd_k
    }{
        \norm{\nabla {f\rnd{\bmx}}_k} \cdot \norm{\bmd_k}
    }
\]
\begin{theorem}[Convergenza dei metodi di ricerca lineare approssimata]
    Sia \(\bmd_k\) una direzione di discesa e sia \(\alpha_k\) una distanza che rispetti le condizioni di Wolfe. Sia inoltre \(f\) una funzione limitata inferiormente su \(\R^n\), \textbf{differenziabile continuamente} sull'insieme \(M\) che contiene \(L_f = \crl{\bmx: f\rnd{\bmx} \leq f\rnd{\bmx_0}}\), dove \(\bmx_0\) è il punto di inizio. Assumiamo inoltre che \(\nabla f\) sia \textbf{lipschitziana} sull'insieme \(M\). Allora:
    \[
        \sum_{j=0}^{\infty} \cos^2 \theta_j \norm{\nabla f \rnd{\bmx_j}}^2 \leq \infty
    \]\end{theorem}

\begin{proof}
    Essendo valida la \textbf{condizione di curvatura}, allora vale la disequazione:
    \[
        \nabla f^T_{k+1} \bmd_k \geq c_2 \nabla f_k^T \bmd_k
    \]    Sottraggo ad ambo i lati \(\nabla f^T_k\bmd_k\) ed ottengo:
    \[
        \rnd{\nabla f_{k+1}-\nabla f_k}^T \bmd_k \geq \rnd{c_2-1} \nabla f_k^T \bmd_k
    \]    Siccome il gradiente della funzione è \textbf{lipschitziano} (non va a infinito in un \(\delta \bmx \)) vale la disequazione:
    \[
        \rnd{\nabla f^T_{k+1}-\nabla f_k}^T \bmd_k \leq \norm{\nabla f^T_{k+1}-\nabla f_k} \norm{\bmd_k} \leq L\norm{\bmx_{k+1} - \bmx_k}\norm{\bmd_k} = \a_k L \norm{\bmd_k}^2
    \]    Da questa disequazione ricaviamo il valore di \(\a_k\):
    \[
        \a_k \geq \frac{c_2 -1}{L} \frac{\nabla f_k^T \bmd_k}{\norm{\bmd_k}^2}
    \]    Essendo quindi valida la \textbf{condizione di decremento sufficiente} vale la disequazione:
    \[
        f_{k+1} \leq f_k + c_1\a_k\bmd_k^T \nabla f_k
    \]    Sostituendo il valore di \(\a_k\) ottenuto al passaggio precedente ottengo:
    \[
        f_{k+1} \leq f_k - c_1 \frac{1-c_2}{L} \frac{\rnd{\nabla f_k^T \bmd_k}^2}{\norm{\bmd_k}^2}
    \]    Pongo \(c = c_1 \frac{1-c_2}{L}\) ed ottengo:
    \[
        f_{k+1} \leq f_k - c \frac{\rnd{\nabla f_k^T \bmd_k}^2}{\norm{\bmd_k}^2}
    \]    Sostituisco \(
    \cos^2 \theta_k = \frac{
        \rnd{-\nabla {f\rnd{\bmx}}_k^T \bmd_k}^2
    }{
        \norm{\nabla {f\rnd{\bmx}}_k}^2 \cdot \norm{\bmd_k}^2
    }
    \) ed ottengo:

    \[
        f_{k+1} \leq f_k - c\cos^2 \theta_k \norm{\nabla f_k}^2
    \]
    Per ricorsione ottengo la sommatoria:

    \[
        f_{k+1} \leq f_0 - c\sum_{j=0}^k\cos^2 \theta_j \norm{\nabla f_j}^2
    \]
    Siccome la funzione \(f\) è limitata inferiormente si ottiene la \textbf{condizione di Zoutendijk}:

    \[
        c\sum_{j=0}^k\cos^2 \theta_j \norm{\nabla f_j}^2 \leq f_0 - f_{k+1} < \infty
    \]
    Questo implica che:

    \[
        \lim_{k\rightarrow \infty} \cos^2 \theta_k \norm{\nabla f_k}^2 \rightarrow 0
    \]
    Quindi se l'algoritmo soddisfa anche la \textbf{condizione angolare} (cioè sceglie una direzione di discesa che la rispetta) \(\cos \theta_k \geq \epsilon > 0\) allora \textbf{converge}:

    \[
        \lim_{k\rightarrow\infty} \norm{\nabla f\rnd{\bmx_k}} = 0
    \]
\end{proof}

\subfile{\main/chapters/programmazione_non_lineare/chapters/metodi_di_ottimizzazione.tex}
\subfile{\main/chapters/programmazione_non_lineare/chapters/ottimizzazione_vincolata.tex}
\subfile{\main/chapters/programmazione_non_lineare/chapters/algoritmi.tex}

\end{document}